<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>004_深度学习实战—手写体识别(mnist)</title>
      <link href="2024/08/28/shen-du-xue-xi-shi-zhan-shou-xie-ti-shi-bie-mnist/04-mnist-shou-xie-ti-shi-bie/"/>
      <url>2024/08/28/shen-du-xue-xi-shi-zhan-shou-xie-ti-shi-bie-mnist/04-mnist-shou-xie-ti-shi-bie/</url>
      
        <content type="html"><![CDATA[<h1 id="MNIST手写体数字识别项目"><a href="#MNIST手写体数字识别项目" class="headerlink" title="MNIST手写体数字识别项目"></a>MNIST手写体数字识别项目</h1><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><p>因为mnist项目耗费的资源并不是很多，所以通常CPU与GPU环境都能运行起来，考虑到初学者可能并没有GPU设备，所以我这里给出了两个环境配置的参数。并且实际下边代码开发过程中，GPU与CPU环境都是可以运行这份代码的。</p><p><strong>CPU环境</strong>：这个很简单，只要你有一个电脑就可以了，然后使用conda创建一个新环境，环境版本配置建议如下：python3.8，pytorch1.9.1，其他的就参考我一开始的配置环境吧：<a href="https://mp.weixin.qq.com/s/mu-ePQBKiWupaZxIXwVCgQ">https://mp.weixin.qq.com/s/mu-ePQBKiWupaZxIXwVCgQ</a></p><p><strong>GPU环境</strong>：这个需要配置cuda驱动，然后安装python3.8，pytorch1.9.1，因为这个安装跟电脑显卡型号相关，大家自己百度吧，网上这种配置文章多的很。</p><h2 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h2><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>对于所有入门深度学习的同学来说，不管你使用的是什么深度学习框架（pytorch，tensorflow，mxnet，caffe等等），mnist手写体识别项目可以说是你人生中的第一个深度学习项目。</p><p>这个项目其实并不是很重要，但是他足够简单，并且涉及到的知识点将会在整个深度学习技术的学习中占据着举足轻重的地位。</p><p>就我个人来说，我一般新拿到一个电脑配置好GPU以及深度学习环境之后，我都会拿mnist项目来先跑一会，验证一下我的电脑配置是否可用。</p><h2 id="理论知识"><a href="#理论知识" class="headerlink" title="理论知识"></a>理论知识</h2><h3 id="项目思路"><a href="#项目思路" class="headerlink" title="项目思路"></a>项目思路</h3><ul><li>首先，我们拿着mnist手写体数字数据集送入我们设计的神经网络。（这个数据集是经过标注的，一个图片中会存在一个手写体数字0~9，并且会有一个标注文件指示出这个图片中的数字是多少）。</li><li>其次，我们使用神经网络去提取数据集中的一个个图片的特征向量，然后再使用特征向量来做类别的预测。</li><li>然后，拿着神经网络预测的类别去和数据集中的真实类别进行损失计算，然后迭代更新参数，直到损失变到最小。</li><li>最后，得到训练好的神经网络参数，来预测输入的图片。</li></ul><p>沿着这个思路，我们首先介绍<strong>mnist数据集</strong>，然后介绍神经网络的设计，然后介绍<strong>训练过程</strong>，然后再介绍预测过程。</p><h3 id="MNIST数据集"><a href="#MNIST数据集" class="headerlink" title="MNIST数据集"></a>MNIST数据集</h3><p>在这里我们需要确立一个思想，深度学习这个技术能够做到的事情是从大量已知的具有标注的数据中，学习对这些数据提取特征，并且基于这些提取到的特征去完成后续的任务。所以这里就会存在一个问题，神经网络的使用前提的我们能够得到数据集。</p><p>废话不多说，我们看看mnist手写体数字数据集长什么样子。</p><img src="./images/1.jpg" style="zoom:67%;" /><p>我们可以看到mnist数据集其实就是手工写的数字，就是有它对应的真实标注。因为这个数据集的图像分辨率只有28x28，所以看着有点糊。</p><p><strong>训练集：</strong>该数据集有60000张训练图像。</p><p><strong>测试集：</strong>该数据集有10000张测试图像。</p><p>训练集与测试集每张图像都有标注，共10个类别，每个类别代表0~9之间的一个数字，每张图像只有一个类别。</p><p>训练集是我们训练神经网络过程中用到的数据，测试集是我们拿训练集训练好的参数来直接推理得到预测结果，用于证明我们训练效果的。通常我们将测试集测试到的结果用来公布，说明我们训练的结果。</p><h3 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h3><p>这里的卷积神经网络要实现的功能如下：</p><p><img src="./images/2.jpg"></p><p>首先，我们<strong>输入</strong>的是一张手写体数字图像，这个图像是灰度图所以他的通道是1（彩色图的通道的3），并且宽高都是28，所以他的维度是1x28x28。其中的B是我们网络训练过程中的batch（批次），它的含义是一次要送入神经网络B张图像（B的大小通常跟显卡的内存大小有关，显卡内存越大，B可以设置的越大）。</p><p>经过组合的<strong>卷积层</strong>（现在理解为卷积层就行，后边代码再细讲），我们将图像的维度从28减少到12，这个时候因为图像维度减少了，也就代表着特征相应减少，所以为了保证特征丰富性，我么将通道由原来的1增加到了10。（在神经网络设计的过程中有一个默认的操作就是特征提取过程中维度逐渐减少，通道逐渐增加）</p><p>第二次经过组合的<strong>卷积层</strong>，我们将图像维度减少到4，将图像通道增加到20。此时的图像特征维度为Bx20x4x4。</p><p>后续为了让数据特征维度Bx20x4x4适应全连接神经网络的输入维度，所以我们会对特征进行<strong>展平</strong>操作，展平后的数据特征为Bx320。（其实就是保持B维度不变，后边3个维度相乘就好了）。</p><p>最后将Bx320送入<strong>全连接</strong>神经网络，进而得到最终的分类特征向量Bx10。其中的10经过概率化处理就可以看作是类别0~9对应的预测概率。</p><p>大致的工作流程就是这样的，其中涉及到的卷积层，全连接等等细节知识请大家看之前写的文章：<a href="https://mp.weixin.qq.com/s/E5XQ-W_wUfESiSkuUVpc1A">https://mp.weixin.qq.com/s/E5XQ-W_wUfESiSkuUVpc1A</a></p><p>下边我们就开始代码实践部分。</p><h2 id="代码实践"><a href="#代码实践" class="headerlink" title="代码实践"></a>代码实践</h2><h3 id="流程分析"><a href="#流程分析" class="headerlink" title="流程分析"></a>流程分析</h3><p>平常我们构建AI算法的时候可以先写<strong>数据加载模块</strong>，然后再<strong>构建模型</strong>，然后再写<strong>模型训练模块</strong>，最后写<strong>模型推理模块</strong>；但是mnist比较简单，其中的数据集可以从pytorch的官方代码中提取，所以这里的数据加载模块就没有单独写出来。所以我这里只写了模型构建，模型训练以及模型推理三部分。其对应的代码如下：</p><p><strong>完整代码放在github仓库</strong>：<code>https://github.com/xiaoxiaojiea/myBlogShare/tree/main/DeepLearning/DL_base/mnist_code</code></p><h3 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h3><p>新建文件 <code>model.py</code> 写入以下内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">@Project ：pycharm_ws </span></span><br><span class="line"><span class="string">@File    ：model.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：Huajie Sun</span></span><br><span class="line"><span class="string">@Date    ：2023/7/10 下午3:11</span></span><br><span class="line"><span class="string">@anno    ：This is a file about  </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 = torch.nn.Sequential(</span><br><span class="line">            torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>),  <span class="comment"># W=（F-K+2P）/S+1</span></span><br><span class="line">            torch.nn.ReLU(),  <span class="comment"># 针对每个channel进行单独的激活</span></span><br><span class="line">            torch.nn.MaxPool2d(kernel_size=<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.conv2 = torch.nn.Sequential(</span><br><span class="line">            torch.nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            torch.nn.MaxPool2d(kernel_size=<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.fc = torch.nn.Sequential(</span><br><span class="line">            torch.nn.Linear(<span class="number">320</span>, <span class="number">50</span>),</span><br><span class="line">            torch.nn.Linear(<span class="number">50</span>, <span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># print(&quot;in: &quot;, x.shape)  # torch.Size([32, 1, 28, 28])</span></span><br><span class="line"></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        x = self.conv1(x)  <span class="comment"># 卷积+激活+池化</span></span><br><span class="line">        <span class="comment"># print(&quot;conv1: &quot;, x.shape)  # torch.Size([32, 10, 12, 12])</span></span><br><span class="line"></span><br><span class="line">        x = self.conv2(x)  <span class="comment"># 卷积+激活+池化</span></span><br><span class="line">        <span class="comment"># print(&quot;conv2: &quot;, x.shape)  # torch.Size([32, 20, 4, 4])</span></span><br><span class="line"></span><br><span class="line">        x = x.view(batch_size, -<span class="number">1</span>)  <span class="comment"># 展平(batch, 20,4,4) ==&gt; (batch, 320)</span></span><br><span class="line">        <span class="comment"># print(&quot;view: &quot;, x.shape)  # torch.Size([32, 320])</span></span><br><span class="line"></span><br><span class="line">        x = self.fc(x)  <span class="comment"># 全连接输出类别长度</span></span><br><span class="line">        <span class="comment"># print(&quot;fc: &quot;, x.shape)  # torch.Size([32, 10])</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x  <span class="comment"># 最后输出的是维度为10的，也就是（对应数学符号的0~9）</span></span><br></pre></td></tr></table></figure><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>新建 <code>train.py</code> 写入以下内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">@Project ：pycharm_ws </span></span><br><span class="line"><span class="string">@File    ：train.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：Huajie Sun</span></span><br><span class="line"><span class="string">@Date    ：2023/7/10 下午3:13</span></span><br><span class="line"><span class="string">@anno    ：This is a file about  </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> Net</span><br><span class="line"></span><br><span class="line"><span class="comment"># device</span></span><br><span class="line"><span class="comment"># device = &quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;</span></span><br><span class="line">device = <span class="string">&quot;cpu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span>(<span class="params">root, batch_size, show=<span class="literal">False</span></span>):</span></span><br><span class="line"></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),  <span class="comment"># 将数据转为pytorch数据类类型（tensor）</span></span><br><span class="line">        transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">        <span class="comment"># 图像归一化：对图像像素值进行预处理，目的是将图像数据缩放到合适的范围或分布。</span></span><br><span class="line">        <span class="comment">#   这样在预测的时候也会把输入的图像按照这个参数进行归一化，防止一些奇怪的数据影响预测准确率。</span></span><br><span class="line">        <span class="comment">#   提高模型的泛化能力。</span></span><br><span class="line">        <span class="comment"># 归一化的方法：</span></span><br><span class="line">        <span class="comment">#   1，最大最小值归一化：将像素值线性缩放到指定的范围，如[0, 1]或[-1, 1]。</span></span><br><span class="line">        <span class="comment">#   2，均值方差归一化：将像素值减去均值，并除以标准差，使得数据分布具有零均值和单位方差。</span></span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一般这一步是需要自己根据实际数据集定义</span></span><br><span class="line">    train_dataset = datasets.MNIST(root=root, train=<span class="literal">True</span>, transform=transform,</span><br><span class="line">                                   download=<span class="literal">True</span>)  <span class="comment"># 本地没有就加上download=True</span></span><br><span class="line">    test_dataset = datasets.MNIST(root=root, train=<span class="literal">False</span>, transform=transform,</span><br><span class="line">                                  download=<span class="literal">True</span>)  <span class="comment"># train=True训练集，=False测试集</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 固定</span></span><br><span class="line">    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> show:</span><br><span class="line">        fig = plt.figure()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>):</span><br><span class="line">            plt.subplot(<span class="number">3</span>, <span class="number">4</span>, i + <span class="number">1</span>)</span><br><span class="line">            plt.tight_layout()</span><br><span class="line">            plt.imshow(train_dataset.train_data[i], cmap=<span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">            plt.title(<span class="string">&quot;Labels: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_dataset.train_labels[i]))</span><br><span class="line">            plt.xticks([])</span><br><span class="line">            plt.yticks([])</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_loader, test_loader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_one_epoch</span>(<span class="params">model, train_loader, criterion, optimizer, epoch</span>):</span></span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span>  <span class="comment"># 这整个epoch的loss清零</span></span><br><span class="line">    running_total = <span class="number">0</span>  <span class="comment"># 处理了多少样本</span></span><br><span class="line">    running_correct = <span class="number">0</span>  <span class="comment"># 正确预测的样本</span></span><br><span class="line"></span><br><span class="line">    train_loader = tqdm.tqdm(train_loader)</span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        inputs, target = inputs.to(device), target.to(device)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + update</span></span><br><span class="line">        outputs = model(inputs.to(device))  <span class="comment"># 推理</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 损失计算</span></span><br><span class="line">        <span class="comment"># print(outputs.shape, target.shape)  # torch.Size([32, 10]) torch.Size([32])</span></span><br><span class="line">        loss = criterion(outputs, target.to(device))</span><br><span class="line"></span><br><span class="line">        loss.backward()  <span class="comment"># 损失后向传播（当前损失对所有节点求导）</span></span><br><span class="line">        optimizer.step()  <span class="comment"># 梯度更新（使用loss对每个节点计算的梯度进行每个结点的参数更新）</span></span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()  <span class="comment"># 累加当前epoch的loss</span></span><br><span class="line"></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)  <span class="comment"># 预测最大概率</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 统计</span></span><br><span class="line">        running_total += inputs.shape[<span class="number">0</span>]  <span class="comment"># 总计数量</span></span><br><span class="line">        running_correct += (predicted == target.to(device)).<span class="built_in">sum</span>().item()  <span class="comment"># 正确预测数量</span></span><br><span class="line"></span><br><span class="line">    acc = running_correct / running_total</span><br><span class="line">    print(<span class="string">&quot;train acc: &quot;</span>, acc)</span><br><span class="line">    </span><br><span class="line">    torch.save(model.state_dict(), <span class="string">&quot;checkpoint_mnist.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> acc</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_one_epoch</span>(<span class="params">model, test_loader, epoch</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 测试集不用算梯度</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            images, labels = images.to(device), labels.to(device)</span><br><span class="line"></span><br><span class="line">            outputs = model(images)</span><br><span class="line"></span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    acc = correct / total</span><br><span class="line">    print(<span class="string">&quot;test acc: &quot;</span>, acc)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> acc</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_acc_fun</span>(<span class="params">train_acc_list, test_acc_list, epochs</span>):</span></span><br><span class="line">    <span class="comment"># 创建数据</span></span><br><span class="line">    epoch_list = [e <span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(epochs)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 画图</span></span><br><span class="line">    plt.plot(epoch_list, train_acc_list, label=<span class="string">&quot;train acc&quot;</span>)</span><br><span class="line">    plt.plot(epoch_list, test_acc_list, label=<span class="string">&quot;test acc&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加标题和标签</span></span><br><span class="line">    plt.title(<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;epochs&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;acc&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示图像</span></span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1，model define</span></span><br><span class="line">    model = Net().to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2，data</span></span><br><span class="line">    root = <span class="string">&quot;./data/mnist&quot;</span></span><br><span class="line">    batch_size = <span class="number">32</span></span><br><span class="line">    train_loader, test_loader = get_data(root, batch_size, show=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loss</span></span><br><span class="line">    criterion = torch.nn.CrossEntropyLoss()  <span class="comment"># 交叉熵损失</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;  适用于分类问题：衡量了预测概率分布与真实概率分布之间的差异</span></span><br><span class="line"><span class="string">        1，预测与label数据维度（都是概率）： out: torch.Size([B, 10]) label: torch.Size([32])</span></span><br><span class="line"><span class="string">        2，CEL使用对数损失进行计算，假设有一个包含C(10)个类别的分类问题，并且对于某个样本，真实类别标签概率用yi表示</span></span><br><span class="line"><span class="string">          （其中i从1到C变化）。每个类别的预测概率由pi表示（同样i从1到C变化），公式如下：</span></span><br><span class="line"><span class="string">          L = -∑(yi * log(pi))</span></span><br><span class="line"><span class="string">          求和是针对所有类别进行的，损失值L对错误的预测给予惩罚，当对于真实类别的预测概率较低时，损失值较高。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># optimizer</span></span><br><span class="line">    learning_rate = <span class="number">0.01</span></span><br><span class="line">    momentum = <span class="number">0.5</span></span><br><span class="line">    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,</span><br><span class="line">                                momentum=momentum)  <span class="comment"># lr学习率，momentum冲量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    show_acc = <span class="literal">True</span></span><br><span class="line">    epochs = <span class="number">5</span></span><br><span class="line">    train_acc_list = []</span><br><span class="line">    test_acc_list = []</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        train_acc = train_one_epoch(model, train_loader, criterion, optimizer, epoch)</span><br><span class="line">        train_acc_list.append(train_acc)</span><br><span class="line"></span><br><span class="line">        test_acc = test_one_epoch(model, test_loader, epoch)</span><br><span class="line">        test_acc_list.append(test_acc)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> show_acc:</span><br><span class="line">        show_acc_fun(train_acc_list, test_acc_list, epochs)</span><br></pre></td></tr></table></figure><h3 id="模型推理"><a href="#模型推理" class="headerlink" title="模型推理"></a>模型推理</h3><p>新建 <code>predict.py</code> 写入以下内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">@Project ：pycharm_ws </span></span><br><span class="line"><span class="string">@File    ：infer.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：Huajie Sun</span></span><br><span class="line"><span class="string">@Date    ：2023/7/19 上午11:28</span></span><br><span class="line"><span class="string">@anno    ：This is a file about 推理</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># from model import Net</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># device</span></span><br><span class="line"><span class="comment"># device = &quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;</span></span><br><span class="line">device = <span class="string">&quot;cpu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span>(<span class="params">image_path</span>):</span></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">        transforms.ToTensor(),  <span class="comment"># 将数据转为pytorch数据类类型（tensor）</span></span><br><span class="line">        transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    image = Image.<span class="built_in">open</span>(image_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 转换为灰度图（因为mnist数据集数据都是灰度图）</span></span><br><span class="line">    gray_image = image.convert(<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    gray_image = transform(gray_image)</span><br><span class="line">    gray_image = gray_image.unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gray_image</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 1，model define</span></span><br><span class="line">    model = Net().to(device)</span><br><span class="line">    checkpoints = <span class="string">&quot;checkpoint_mnist.pth&quot;</span></span><br><span class="line">    model.load_state_dict(torch.load(checkpoints))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># data</span></span><br><span class="line">    image_path = <span class="string">&quot;./test.png&quot;</span></span><br><span class="line">    image = get_data(image_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># infer</span></span><br><span class="line">    outputs = model(image.to(device))</span><br><span class="line">    _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">    print(predicted.data)</span><br></pre></td></tr></table></figure><p>使用到的测试图像如下：</p><p><img src="images/test.png"></p><p>这个测试图像是我使用win10的画图工具写的，写的时候一定要保证数据与mnist数据集的格式一致，比如：黑底白字，尺寸为28x28。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本节首先介绍了手写体识别的理论知识，然后根据常用的代码组织思路给出了示例代码，并且使用训练后的权重对自己手写的数字做出了识别。</p><p>最后希望大家把上边的代码彻底吃透，基础很重要。</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ncnn安装与样例代码跑通</title>
      <link href="2022/09/05/ncnn-an-zhuang-yu-yang-li-dai-ma-pao-tong/"/>
      <url>2022/09/05/ncnn-an-zhuang-yu-yang-li-dai-ma-pao-tong/</url>
      
        <content type="html"><![CDATA[<h1 id="ncnn安装与样例代码跑通"><a href="#ncnn安装与样例代码跑通" class="headerlink" title="ncnn安装与样例代码跑通"></a>ncnn安装与样例代码跑通</h1><ul><li>首先将pytorch转为onnx文件</li><li>然后将onnx转为ncnn文件<ul><li>下载官方的代码：<a href="https://github.com/Tencent/ncnn">https://github.com/Tencent/ncnn</a> （官方有不同设备的安装方法，下边只是针对ubuntu）</li><li>安装依赖环境：sudo apt install build-essential git cmake libprotobuf-dev protobuf-compiler libvulkan-dev vulkan-utils libopencv-dev<ul><li>git clone ncnn</li><li>cd ncnn</li><li>mkdir -p build</li><li>cd build</li><li>cmake -DCMAKE_BUILD_TYPE=Release DNCNN_VULKAN=ON DNCNN_SYSTEM_GLSLANG=ON DNCNN_BUILD_EXAMPLES=ON ..</li><li>make -j24</li></ul></li><li>验证安装：<ul><li>build$ cd ../examples</li><li>examples$ ../build/examples/squeezenet ../images/256-ncnn.png<ul><li>[0 AMD RADV FIJI (LLVM 10.0.1)]  queueC=1[4]  queueG=0[1]  queueT=0[1]</li><li>[0 AMD RADV FIJI (LLVM 10.0.1)]  bugsbn1=0  buglbia=0  bugcopc=0  bugihfa=0</li><li>[0 AMD RADV FIJI (LLVM 10.0.1)]  fp16p=1  fp16s=1  fp16a=0  int8s=1  int8a=1</li><li>532 = 0.163452</li><li>920 = 0.093140</li><li>716 = 0.061584</li></ul></li><li>如果出现终端打印出这些信息就说明安装成功</li></ul></li><li>简化onnx模型，以免出现不可编译的情况<ul><li>pip install onnx-simplifier</li><li>python3 -m onnxsim my_mobileface.onnx my_mobileface-sim.onnx<ul><li>这里报错cuda的话，就注意他的cuda版本</li></ul></li><li>onnx转换为ncnn，需要使用在ncnn/build/tools/onnx2ncnn<ul><li>./onnx2ncnn my_mobileface-sim.onnx my_mobileface.param my_mobileface.bin</li><li>生成的.bin与.param文件就是我们在ubuntu上需要使用的NCNN模型文件</li></ul></li></ul></li></ul></li><li>使用ncnn的param、bin文件进行推理：<ul><li>进入ncnn的源码生成param与bin文件： cd build/tools/onnx<ul><li>cd tools/onnx</li><li>./onnx example.onnx example.parm example.bin</li></ul></li><li>编译文件（ncnn目录下）：<ul><li>mkdir  build</li><li>cd build</li><li>cmake ..</li><li>make -j4</li></ul></li><li>编译成功后会在当前目录生成examples目录,执行测试代码<ul><li>cp ../examples/squeezenet_v1.1.param examples/</li><li>cp ../examples/squeezenet_v1.1.bin examples/</li><li>./squeezent test.jpg</li><li>运行成功会显示top-3的类别id和概率值.</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 笔记杂文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模型部署 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorrt7+cuda10.2+cudnn7.6环境配置与样例运行</title>
      <link href="2022/09/03/tensorrt7-cuda10.2-cudnn7.6-huan-jing-pei-zhi-yu-yang-li-yun-xing/"/>
      <url>2022/09/03/tensorrt7-cuda10.2-cudnn7.6-huan-jing-pei-zhi-yu-yang-li-yun-xing/</url>
      
        <content type="html"><![CDATA[<h1 id="tensorrt7-cuda10-2-cudnn7-6环境配置与样例运行"><a href="#tensorrt7-cuda10-2-cudnn7-6环境配置与样例运行" class="headerlink" title="tensorrt7+cuda10.2+cudnn7.6环境配置与样例运行"></a>tensorrt7+cuda10.2+cudnn7.6环境配置与样例运行</h1><ul><li><p>首先下载trt的源码： <code>TensorRT-7.0.0.11.Ubuntu-18.04.x86_64-gnu.cuda-10.2.cudnn7.6.tar.gz</code></p><ul><li>下载地址：<code>https://developer.nvidia.com/nvidia-tensorrt-7x-download</code></li></ul></li><li><p>下载好之后就可以把源码解压放到文件夹中<code>/usr/local</code> （下边会将该路径配置到系统库路径）</p><blockquote><p>trt+cuda+cudnn的版本一定要有对应关系。</p></blockquote></li><li><p>然后trt下载的文件名字中就可以发现需要cuda10.2，cudnn7.6,所以就要去对应上自己环境信息。</p><blockquote><p>我自己系统装了cuda10.1版本，然后我又去下载了cuda10.2的版本（<code>https://developer.nvidia.com/cuda-10.2-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=1804&amp;target_type=runfilelocal</code>），安装的时候不要选择安装驱动，因为我已经装过了，安装好的10.2cuda版本存在<code>/usr/local/</code> 下边，然后我们就需要将使用的cuda-10.2形成新的软连接</p></blockquote><ul><li>删除原来的软链接，需要在 /usr/local 目录下：<code>sudo rm -rf /usr/local/cuda</code></li><li>创建新的软链接，cuda-10.2 换成你需要的版本（已安装）：<code>sudo ln -s /usr/local/cuda-10.2 /usr/local/cuda</code></li><li>验证操作，查看新的软链接的指向内容：sudo stat /usr/local/cuda</li></ul></li><li><p>然后去官网下载cudnn7.6的压缩包（<code>https://developer.nvidia.com/rdp/cudnn-archive</code>），版本的话选择（<code>cudnn-10.2-linux-x64-v7.6.5.32.tgz</code>），然后使用一下命令来处理</p><ul><li>解压下载的文件，可以看到cuda文件夹，在当前目录打开终端，执行如下命令：<ul><li><code>sudo cp cuda/include/cudnn.h /usr/local/cuda/include/</code></li><li><code>sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/</code></li><li><code>sudo chmod a+r /usr/local/cuda/include/cudnn.h</code></li><li><code>sudo chmod a+r /usr/local/cuda/lib64/libcudnn*</code></li></ul></li></ul></li><li><p>然后就需要<code>sudo gedit ~/.bashrc</code> 中加入一下信息：</p><ul><li>加入cuda配置<ul><li><code>export CUDA_HOME=/usr/local/cuda</code></li><li><code>export PATH=$PATH:$CUDA_HOME/bin</code></li><li><code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CUDA_HOME/lib64</code></li></ul></li><li>tensorrt<ul><li><code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/TensorRT-7.0.0.11/lib</code></li></ul></li></ul></li><li><p>到这里的话基本上就没啥问题了，然后进入到<code>/home/jie/下载/TensorRT-7.0.0.11.Ubuntu-18.04.x86_64-gnu.cuda-10.2.cudnn7.6/TensorRT-7.0.0.11/data/mnist</code>目录下，执行<code>download_pgms.py</code>文件，下载待测试的mnist数据，</p></li><li><p>然后进入<code>/home/jie/下载/TensorRT-7.0.0.11.Ubuntu-18.04.x86_64-gnu.cuda-10.2.cudnn7.6/TensorRT-7.0.0.11/samples/sampleOnnxMNIST</code>执行<code>make</code>，就会在<code>../../bin</code>中生成可执行文件，就能执行了。</p></li><li><p>tips:</p><ul><li>trt对cuda，cudnn版本要求非常高</li><li>安装的cuda，tensort都放在了<code>/usr/local</code>文件夹下边，并且cudnn是放在了cuda中</li><li>cuda与trt的路径必须配置到系统自带的动态链接库中<code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CUDA_HOME/lib64</code>命令就是将该文件夹下边的内容加入到ubuntu系统的动态连接库中</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 笔记杂文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模型部署 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>003-深度学习编码基础(PyTorch，卷积，池化，全连接，激活函数)</title>
      <link href="2022/08/28/shen-du-xue-xi-bian-ma-ji-chu/"/>
      <url>2022/08/28/shen-du-xue-xi-bian-ma-ji-chu/</url>
      
        <content type="html"><![CDATA[<h1 id="003-深度学习编码基础-PyTorch，卷积，池化，全连接，激活函数"><a href="#003-深度学习编码基础-PyTorch，卷积，池化，全连接，激活函数" class="headerlink" title="003-深度学习编码基础(PyTorch，卷积，池化，全连接，激活函数)"></a>003-深度学习编码基础(PyTorch，卷积，池化，全连接，激活函数)</h1><blockquote><p>在上边讲完了深度学习的基础知识以及数学基础之后，下边就要学习一些代码编写的基础了。</p><p>这里主要是使用 <strong>PyTorch</strong> 框架进行的。</p></blockquote><p><strong>本节目录如下：</strong></p><ul><li>前言。</li><li>全连接层。</li><li>卷积层。</li><li>池化层。</li><li>激活函数。</li><li>Softmax。</li></ul><h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h2><p>前两节我们已经结束掉了基础知识的讲解，接下来的任务就是讲解一些代码的编写基础。</p><p>这里边的代码编写起始就是想方设法的把前文中提到的基础知识转化为计算机运算而已，所以如果你看明白了前那边的基础知识，这里就是简单的思维转换一下而已。</p><p>这里主要使用<strong>python</strong>语言，深度学习框架主要使用的是<strong>pytorch</strong>。</p><blockquote><p>python与pytorch的安装已经在第一节介绍过了。</p></blockquote><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&amp;mid=2247485688&amp;idx=1&amp;sn=78c9635614ba7ec6afa630e4e47f5bb1&amp;chksm=fca93fbacbdeb6ac247782a330cd55fa8713cf1ed3ff8a464f3f96c60b12da3d57ed2909f6b7&token=500243106&lang=zh_CN#rd">基础环境安装</a></p><h2 id="1-全连接层"><a href="#1-全连接层" class="headerlink" title="1. 全连接层"></a>1. 全连接层</h2><p>大家应该还记得这张图：</p><img src="https://i.loli.net/2021/11/05/CYiaxvQtnq51hM9.png" alt="image-20210331220912454" style="zoom:80%;" /><p>这张图表达的内容就是全连接层所要表达的含义：总共有x1，x2，11，12，13，21六个节点，x1，x2两个节点属于输入层，11，12，13三个节点称之为隐藏层，21属于输出层。</p><p>他们之间的传递关系是：输入数据—&gt;隐藏层—&gt;输出。我们可以发现相邻两层之间的节点是全部进行两两连接的，这种情况我们就称之为全连接，这也就是全连接的来由。</p><p>各层之间的节点连接的目的是，想让整个全连接网络求出两两节点之间的权重，当网络学习到了一组较好的权重之后就可以使用这组权重+这组网络来预测未来的输入x1，x2.</p><p><strong>所以，应该怎样用pytorch代码来表示全连接层呢？</strong></p><p>很简单，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn  <span class="comment"># 导入torch的nn模块</span></span><br><span class="line"></span><br><span class="line">linear1 = nn.Linear(in_features=<span class="number">2</span>, out_features=<span class="number">3</span>)  <span class="comment"># 使用nn模块创建一个全连接层（第一层(x1,x2)到第二层(11,12,13)之间的全连接）,第一个参数就是第一层的节点数，第二个参数就是第二层的节点数。</span></span><br><span class="line"></span><br><span class="line">linear2 = nn.Linear(in_features=<span class="number">3</span>, out_features=<span class="number">1</span>)  <span class="comment"># 使用nn模块创建一个全连接层（第二层(11,12,13)到第三层(21)之间的全连接）,第一个参数就是第二层的节点数，第二个参数就是第三层的节点数。</span></span><br></pre></td></tr></table></figure><p>经过这样的代码表示，可以得到的信息是<code>linear1</code>中的参数就是<code>2x3</code>个（其实还有一个偏差，这里就不细讲了），<code>linear2</code>中的参数就是<code>3x1</code>个。这些参数就是待优化求解的参数。</p><h2 id="2-卷积层"><a href="#2-卷积层" class="headerlink" title="2. 卷积层"></a>2. 卷积层</h2><p>上边的全连接层在实际的应用中一般都是用于向量之间的优化（上边的每一层数据都是列向量），但是实际生活中二维数据比较常见，而且再加上全连接层之间的参数量太大了（两个列向量之间全连接，每个连接之间都有一个参数，所以参数两太大了），所以提出了卷积层先处理二维图像，给图像提取深度特征并且降维处理，再使用全连接层提取特征。</p><p><strong>卷积层对图像处理可视化如下：</strong></p><p><img src="https://raw.githubusercontent.com/xiaoxiaojiea/img_bed/main/img/image-20220821225746205.png"></p><p>从上边的处理流程可以看出来当我们给定一张<code>12*7</code>的图像，给定一个<code>3*3</code>的卷积核，则卷积核的作用就是类似于滑动窗口的方式遍历图像中的所有像素，然后卷积核框中的地方就会将图像像素值与卷积核的权重值相乘，形成一个数据值。</p><p><strong>卷积核对图像数据卷积处理如下图：</strong></p><img src="https://s2.loli.net/2022/08/28/H2hv59uWjYrNVTg.png" alt="image-20220821231543555" style="zoom:80%;" /><p>针对图像的每一块经过卷积核处理之后都会得到新的特征值，然后整个图像都被卷积之后，图像维度就会减少了，但是图像会被提取到深度特征。</p><p><code>3*3</code>的卷积核处理完<code>12*7</code>的图像之后，图像就会变成<code>10*5</code>维度的。</p><p>这就是卷积核的处理过程，对图像特征进行了深度提取，并且给图像也降低了维度，此时待学习的参数就是<code>3*3</code>卷积核里边每个位置对应的数据值（也就是9个数），这相对于全连接层而言，参数量少了很多。</p><p><strong>所以，应该怎样用pytorch代码来表示卷积层呢？</strong></p><p>很简单，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn  <span class="comment"># 导入torch的nn模块</span></span><br><span class="line"></span><br><span class="line">conv1 = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># in_channels表示的是输入图像的通道(彩色图像就是RGB通道的，灰度图像就是单通道)，输入图像的in_channels是根据输入图像实际情况而定的，这个没得更改。</span></span><br><span class="line"><span class="comment"># out_channels表示你想把输入通道的图像升维到多少维度的通道，升高输入图像通道维度的目的是增加图像的信息提取能力，因为卷积过程中图像的尺寸在变小，为了防止特征越来越少，所以就提升通道维度。</span></span><br><span class="line"><span class="comment"># kernel_size就是卷积核的大小</span></span><br><span class="line"><span class="comment"># stride就是卷积核每次在图像中往右/往下滑动的距离</span></span><br><span class="line"><span class="comment"># padding当图像的宽高不能让卷积核正好覆盖的时候，可以使用该参数对图像填充0</span></span><br></pre></td></tr></table></figure><h2 id="3-池化层"><a href="#3-池化层" class="headerlink" title="3. 池化层"></a>3. 池化层</h2><p>上文介绍的全连接层与池化层都是会学习权重，并用权重来作用到输入数据中，此时我们介绍一个新的操作—池化层，他的特性就是能改处理输入数据（改变维度），但是不学习权重（也就是简单粗暴的修改输入数据维度）。</p><p><strong>池化层其实与卷积层是一个样子，但是他处理数据的时候不学习权重，具体实现如下：</strong></p><img src="https://s2.loli.net/2022/08/28/UCufksrbzIeWaGl.png" alt="image-20220828161945506" style="zoom:67%;" /><p>针对图像中的某一块区域，卷积核的作用就是学习卷积核大小维度的权重参数，然后将权重参数作用到各个像素中，再求出总和即可。但是池化层的作用虽然也是同样的处理，但是池化层不需要学习参数，最大池化就是取出范围内数据的最大值，平均池化就是取出范围内的平均值即可。</p><p><strong>pytorch的池化层代码如下所示：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn  <span class="comment"># 导入torch的nn模块</span></span><br><span class="line"></span><br><span class="line">m = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>)  <span class="comment"># MaxPool2d就是最大池化层，他的2d的意思就是他是二维卷积核</span></span><br><span class="line"><span class="comment"># 3的意思就是这个池化核的尺寸时3*3的，其实你也可以写 (3, 3) </span></span><br><span class="line"><span class="comment"># stride=2的意思就是当前池化核处理完之后，池化核移动多少像素（这里是移动2个像素）。</span></span><br><span class="line">m = nn.AvgPool2d(<span class="number">3</span>, stride=<span class="number">2</span>)  <span class="comment"># AvgPool2d就是平均池化层</span></span><br></pre></td></tr></table></figure><h2 id="4-激活函数"><a href="#4-激活函数" class="headerlink" title="4. 激活函数"></a>4. 激活函数</h2><p>训练过程中神经网络的可能会由于学习权重的变化，使得学习到的数据范围发生巨大的变化（比如说出现极大的负数，但是对于图像像素值来说是不可能出现负数的），所以就需要一定的策略来处理这些数据，所以就出现了激活函数。</p><p><strong>这里简单的介绍ReLU激活函数，他的处理思路如下图：</strong></p><p><img src="https://s2.loli.net/2022/08/28/muewJS6Tghyl1PY.png" alt="image-20220828163702257"></p><p>思路很简单，负数全部给他变为0，正数不改变即可。</p><p><strong>pytorch中的ReLU激活函数的使用如下：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn  <span class="comment"># 导入torch的nn模块</span></span><br><span class="line"></span><br><span class="line">nn.ReLU()  <span class="comment"># 显而易见，没啥说的</span></span><br></pre></td></tr></table></figure><h2 id="5-Softmax"><a href="#5-Softmax" class="headerlink" title="5. Softmax"></a>5. Softmax</h2><p>对于分类问题最终的输出应该是对每个类别预测的概率值（比如10个类别，那么最后应该输出10个数据，每个数据都是表明当前输入是对应类别的概率），但是全连接层输出不可能是概率值，所以就把全连接层最终输出的向量通过softmax转化为整体概率为1概率值。</p><p><strong>softmax的数学思想如下：</strong></p><img src="https://s2.loli.net/2022/08/28/A13BzhGvpNPDwTe.png" alt="image-20220828165144383" style="zoom:67%;" /><p>softmax的思想其实很简单，就是把输入数据的exp相加作为分母，然后对应输入数据的exp除以分母就好了，这样就可以转换出概率值了（至于为什么数据都要用exp，因为防止数据大小出现很大的差距）。</p><p><strong>pytorch中的Softmax的使用如下：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn  <span class="comment"># 导入torch的nn模块</span></span><br><span class="line"></span><br><span class="line">self.softmax = nn.Softmax(dim=<span class="number">1</span>)  <span class="comment"># dim=1的意思是沿着数据的第二维度来做概率化操作</span></span><br></pre></td></tr></table></figure><h2 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h2><p>整个项目开始前，每个模块的组件都是这样了，下一节就准备开始做一个经典的项目<strong>MNIST手写数字体识别</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu18.04安装samba并使用windows连接</title>
      <link href="2022/04/15/ubuntu18.04-an-zhuang-samba-bing-shi-yong-windows-lian-jie/"/>
      <url>2022/04/15/ubuntu18.04-an-zhuang-samba-bing-shi-yong-windows-lian-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="Ubuntu18-04安装samba并使用windows连接"><a href="#Ubuntu18-04安装samba并使用windows连接" class="headerlink" title="Ubuntu18.04安装samba并使用windows连接"></a>Ubuntu18.04安装samba并使用windows连接</h1><h2 id="ubuntu18-04安装samba服务"><a href="#ubuntu18-04安装samba服务" class="headerlink" title="ubuntu18.04安装samba服务"></a>ubuntu18.04安装samba服务</h2><h2 id="ubuntu18-04设置共享文件夹"><a href="#ubuntu18-04设置共享文件夹" class="headerlink" title="ubuntu18.04设置共享文件夹"></a>ubuntu18.04设置共享文件夹</h2><h3 id="windows连接Ubuntu18-04共享文件夹"><a href="#windows连接Ubuntu18-04共享文件夹" class="headerlink" title="windows连接Ubuntu18.04共享文件夹"></a>windows连接Ubuntu18.04共享文件夹</h3>]]></content>
      
      
      <categories>
          
          <category> 工具教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-生成对抗GAN</title>
      <link href="2022/04/08/lun-wen-jing-du-sheng-cheng-dui-kang-gan/"/>
      <url>2022/04/08/lun-wen-jing-du-sheng-cheng-dui-kang-gan/</url>
      
        <content type="html"><![CDATA[<h1 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h1><p>论文题目：<strong>Generative Adversarial Nets</strong></p><p>年份：<strong>2014</strong></p><p>作者：<strong>Ian J. Goodfellow, Jean Pouget-Abadie , Mehdi Mirza,</strong></p><p>档次：<strong>顶会</strong></p><p>论文pdf：</p><p>论文代码：</p>]]></content>
      
      
      <categories>
          
          <category> 生成对抗 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文精读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>002-深度学习数学基础(神经网络、梯度下降、损失函数)</title>
      <link href="2021/04/09/shen-du-xue-xi-shu-xue-ji-chu/"/>
      <url>2021/04/09/shen-du-xue-xi-shu-xue-ji-chu/</url>
      
        <content type="html"><![CDATA[<h1 id="002-深度学习数学基础-神经网络、梯度下降、损失函数"><a href="#002-深度学习数学基础-神经网络、梯度下降、损失函数" class="headerlink" title="002-深度学习数学基础(神经网络、梯度下降、损失函数)"></a>002-深度学习数学基础(神经网络、梯度下降、损失函数)</h1><blockquote><p>这里在进入人工智能的讲解之前，你必须知道几个名词，其实也就是要简单了解一下人工智能的数学基础，不然就真的没办法往下讲了。</p></blockquote><p><strong>本节目录如下：</strong></p><ul><li>前言。</li><li>监督学习与无监督学习。</li><li>神经网络。</li><li>损失函数。</li><li>梯度下降。</li></ul><h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h2><blockquote><p>人工智能可以归结于一句话：<strong>针对特定的任务，找出合适的数学表达式，然后一直优化表达式，直到这个表达式可以用来预测未来</strong>。</p></blockquote><p><strong>接下来就来一句一句的分析这句话：</strong></p><ul><li><strong>针对特定的任务：</strong></li></ul><p>首先我们需要知道的是，人工智能其实就是为了让计算机看起来像人一样智能，为什么这么说呢？举一个人工智能的例子：</p><blockquote><p>我们人看到一个动物的图片，就可以立刻知道这个动物是猫，还是狗。但是计算机却不可以，如果计算机可以分出类别，那么这就会是一个具有图像分类功能的人工智能小例子。</p></blockquote><p>这里的<code>图像分类</code>就是我们所说的特定任务，这就是我们希望写出一个人工智能的程序来做的事情。</p><p>还有一些其他的常见的任务：<code>人脸识别</code>,<code>目标检测</code>,<code>图像分割</code>,<code>自然语言处理</code> 等等。</p><ul><li><strong>找出合适的数学表达式：</strong></li></ul><p>学过高等数学并且有计算机思维的人都知道，世界中几乎所有的事情都可以用数学函数来表达出来，我们先不管这个数学表达式是离散还是连续，也不管他的次数多高，反正他能达到表示特定任务的一种目的。</p><p>比如说，针对一个西瓜质量好坏的预测任务，可以设出以下的表达式：</p><p><img src="https://i.loli.net/2021/04/09/4YclPwSM8dviqOy.png"></p><p><strong>解释如下：</strong></p><blockquote><p>1、<code>x1，x2，x3</code> 可以看作判断西瓜好坏的判断依据，比如可以是：瓜皮纹路，敲击声音，瓜皮颜色等等。</p><p>2、<code>a，b，c，d​</code> 就是这个表达式的系数，一旦数学表达式定下来了，那么接下来需要做的事情就是找出合适的系数，使得这个表达式可以很好的判断出西瓜质量的好坏。</p></blockquote><p>所以，针对上文提到的特定任务，都可以用数学表达式表示出来，当然，我们会尽可能找简单、高效的表达式。</p><ul><li><strong>一直优化这个表达式：</strong></li></ul><p>上边引出表达式之后，会发现当表达式确定下来之后，就要<strong>寻找合适的系数</strong>了，寻找系数的过程就被称之为训练网络的过程。</p><p>我们优化表达式的重要思想是：<strong>一直调整系数值，使得预测出的数据 与 真实数据之间的差距尽可能的最小。</strong> </p><p>比如：假设<strong>预测的数据</strong>是 <code>f1(x)​</code>，<strong>真实数据</strong>是​<code>y</code>，我们通过一直改变系数的值，来找出可以使得预测数据与真实数据之间距离最小的一组，最小的一组数据就是我们需要的系数。</p><p>其中，距离计算公式可以是如下的表达式：</p><p><img src="https://i.loli.net/2021/04/09/Qunjws9EULK4dOJ.png"></p><p>通过这个表达式，得到的 <code>loss</code> 值就是真实值与预测值之间的距离。</p><p>然后，接下来的优化就是针对这个<code>loss</code> 表达式来进行的，目的就是让<code>loss</code>的值达到最小。</p><p>因为<code>loss</code>值达到最小的时候，就意味着我们的预测值与真实值距离很相近，预测越准确。</p><blockquote><p>这里值得一提的是，这里的<code>loss</code>表达式的优化过程，其实就是将<code>loss</code>公式对函数<code>f(x)</code>的系数求导。</p><p>所以当<code>loss</code>最小的时候，就意味着此时的系数最合适。</p><p>具体的细节往下看。</p></blockquote><ul><li><strong>用优化好的表达式预测未来：</strong></li></ul><p>经过上边的优化，此时函数会得到一个相对好一点的系数，然后就可以使用这个函数来预测未来的事情了。</p><p>这就是达到了人工只能的目的了。</p><p><strong>所以，下边我们就要仔细讨论，数学表达式的构建，距离函数的构建，距离的优化。</strong></p><h2 id="1-神经网络"><a href="#1-神经网络" class="headerlink" title="1. 神经网络"></a>1. 神经网络</h2><blockquote><p>神经网络的英文是：neural network （简称：NN）。</p></blockquote><p>神经网络其实就是变形的数学表达式，它通过拼装基础组件（神经元）来<strong>模拟出数学表达式</strong>。</p><h3 id="1-01-什么是神经网络"><a href="#1-01-什么是神经网络" class="headerlink" title="1.01. 什么是神经网络"></a>1.01. 什么是神经网络</h3><p>一说神经网络，大家首先想到的就是神经元，其实没错，神经网络这个名词就是从神经元这里演变过来的。所以我们做一下类比。</p><h4 id="1-01-001-神经元"><a href="#1-01-001-神经元" class="headerlink" title="1.01.001. 神经元"></a>1.01.001. 神经元</h4><p><img src="https://i.loli.net/2021/03/29/ysg85QiHoOxeWRV.png"></p><p>如图所示，这个图就是我们人体的神经元的放大图。</p><p>通常我们身体的 <code>A</code> 部位发出的命令，要指挥 <code>B</code> 部位响应，就要通过 <code>A</code> 向 <code>B</code> 发出信号。这个信号的强弱影响着 <code>B</code> 反应的强弱。</p><p>所以，这就是神经网络的构思所在：</p><p><strong>构建出一个类似于神经元的结构，上一个节点的输入（A处的控制）  以及权重（信号的强弱）共同决定下一个节点的输出（B处的反应）</strong>。</p><blockquote><p>这句话，现在看不懂没关系，有个印象就好，继续往下看吧。</p></blockquote><h4 id="1-01-002-神经网络"><a href="#1-01-002-神经网络" class="headerlink" title="1.01.002. 神经网络"></a>1.01.002. 神经网络</h4><p><img src="https://i.loli.net/2021/03/29/FczJ3p14VZLlKMO.png"></p><p>如图所示就是一个最简单的神经网络结构，这个结构的数学表达式是：<img src="https://i.loli.net/2021/04/09/XdAKBHbCUQIo9px.png"  style="zoom:70%;" /></p><p>图中的圆圈我们就把他类比于神经元，图中的各个结构解释如下：</p><ul><li><p>其中 <code>X1,X2</code> 就是这个神经网络的<strong>输入</strong>，他相当于就是人体大脑发出的控制命令。</p></li><li><p><code>W1,W2</code> 就是<strong>权重</strong>，他是用来控制不同输入信号占比大小的数据，比如：想让控制<code>X1</code>作用明显一点，那么对应的<code>W1</code>就大一点。</p></li><li><p><code>Y</code> 就是<strong>输出</strong>，他就是输入数据与权重作用之后的最终结果，在神经元中也就是最终对身体某个部位的控制信号。</p></li></ul><h3 id="1-02-神经网络的数学原理"><a href="#1-02-神经网络的数学原理" class="headerlink" title="1.02. 神经网络的数学原理"></a>1.02. 神经网络的数学原理</h3><p>神经网络的数学原理非常简单，简单总结下来就是一句话：<strong>不同的输入</strong>作用于<strong>各自的权重</strong>之后<strong>的和</strong>即为我们需要的结果。</p><blockquote><p>其实就可以大致理解为我们的函数 ： <code>f(x) = a*x1 + b*x2</code>  一样，所谓的权重就是我们方程的系数。</p></blockquote><p>细心的人观察上边的公式就会发现，一<strong>个神经元节点</strong>就可以<strong>归结于一个运算式子</strong>。所以我们这里就来针对上图，分析分析含有一个神经元节点的公式。</p><p><img src="https://i.loli.net/2021/03/29/HLDajpEdmXc6tIe.png"></p><p>从图中可以看得出来，最终的输出结果 <code>Y</code> 是由 <code>输入（X）</code> 以及 <code>权重（W）</code> 共同决定的。</p><p>他们最终的计算结果 <code>Y</code> 其实说白了就是一个计算公式：<code>Y = X1*W1 + X2*W2​</code> ，这个公式的含义大家应该都明白，<strong>给不同的输入 分配不同的权重 ，从而得到想要的结果。</strong> </p><p>这就是神经网络中一个神经元的数学原理，当把神经元的个数增多之后，原理以此类推，只不过是要增加权重<code>W</code>以及输入<code>X</code>的个数而已。</p><p><strong>下边就可以看作是一个，含有两层的神经网络结构。</strong></p><p><img src="https://i.loli.net/2021/03/31/a7NpeEBdL5Wcomv.png"></p><ul><li><p>第一层节点： <code>11</code>，<code>12</code>，<code>13 </code>   。第二层节点： <code>21</code>  。</p></li><li><p>输入： <code>X1</code> ，<code>X2</code> 。  输出 ： <code>Y</code>  。</p></li></ul><p>于是，根据公式：<strong>输出</strong> 等于 <strong>输入</strong>作用于 <strong>权重</strong>， 得出以下推导 ：</p><ul><li>输入： <code>X1</code> ，<code>X2</code> 。</li><li>节点<code>11</code>的值： <img src="https://i.loli.net/2021/04/09/1qwb8Dn7c4FHvJV.png"  style="zoom:70%;" /> .</li><li>节点<code>12</code>的值： <img src="https://i.loli.net/2021/04/09/qkaxWFe4H1b7KjZ.png" style="zoom:70%;" />.</li><li>节点<code>13</code>的值： <img src="https://i.loli.net/2021/04/09/sSjNMoHmGXfK5Fh.png"  style="zoom:70%;" />.</li><li>节点<code>21</code>的值就是最终输出 <code>Y</code> ： <img src="https://i.loli.net/2021/04/09/E7dKWXitOcwQJSk.png"  style="zoom:70%;" /> .</li></ul><p><strong>所以，最终的整合式子为：</strong> </p><p><img src="https://i.loli.net/2021/04/09/R2Y7AgvJdikwSFI.png"></p><p><strong>于是，我们可以发现，类似于这样的堆叠方式，我们可以组合成很多的数学函数。</strong></p><blockquote><p>这就是神经网络，他的目的在于将数学公式堆砌出来，至于为什么要这样堆砌，是因为<strong>这样堆砌计算机计算比较方便</strong>呗。 </p></blockquote><h3 id="1-03-总结"><a href="#1-03-总结" class="headerlink" title="1.03 总结"></a>1.03 总结</h3><p>到目前为止你已经知道了神经网络的由来，并且知道神经网络与数学公式之间的关系。</p><p><strong>此时你需要明确的知识点是：</strong></p><ul><li><strong>人工智能就是使用已有的数据，拟合出一个可以用来预测未来的公式。</strong></li><li><strong>这个公式的系数需要一直调整，从而找出一组最为合适，正确率较高的系数。</strong></li><li><strong>因为系数的寻找需要大量的计算，所以需要将这个公式用神经网络表示出来的，因为在计算机中这样表示的时候计算最为方便。</strong></li></ul><h2 id="2-监督学习与无监督学习"><a href="#2-监督学习与无监督学习" class="headerlink" title="2. 监督学习与无监督学习"></a>2. 监督学习与无监督学习</h2><blockquote><p>这个知识点比较简单，就一些单纯的概念。</p></blockquote><p><strong>监督学习</strong>：就是我们收集到的数据是有标签的。</p><blockquote><p>就是说，我们收集到的数据是已经分好类的。</p><p>比如说：当前当前有一批样本数据，</p><ul><li> <code>x1, x2, x6, x9, x13</code>属于类别<code>y1</code>类。</li><li> <code>x3, x4, x5, x8, x11</code>属于类别<code>y2</code>类。</li><li> <code>x7, x10, x12</code>属于类别<code>y3</code>类。</li></ul></blockquote><p>然后接下来我们使用这些数据的时候，就可以使用已有标签的数据，去拟合出曲线，用以预测未来。</p><p><strong>无监督学习</strong>：我们收集到的数据是无标签的。</p><blockquote><p>就是说，收集到的数据并没有固定的类别，我们需要做的事情就是挖掘数据内部的联系，给他们聚类，找出类别。</p></blockquote><p><img src="https://i.loli.net/2021/04/09/bew3KUM8YBiCL69.png"></p><p>如图所示，挖掘出数据内部的联系，让他自动归类。</p><h2 id="3-损失函数"><a href="#3-损失函数" class="headerlink" title="3. 损失函数"></a>3. 损失函数</h2><blockquote><p>上边解释过了，损失函数的作用就是计算 <strong>真实值</strong> 与 <strong>预测值</strong> 之间距离的 （距离其实可以简单理解为两个数据之间的差距）。</p></blockquote><p>这里介绍一些常见的几种损失函数，以供大家入门使用。</p><h3 id="3-01-一些前提"><a href="#3-01-一些前提" class="headerlink" title="3.01. 一些前提"></a>3.01. 一些前提</h3><blockquote><p>这里给定一些大前提，下边的几种损失函数通用的那种。</p></blockquote><ul><li><strong>真实值</strong>：<code>y</code> ，他就是针对某一组输入<code>x</code>的真实标签。</li><li><strong>预测值</strong>：<code>f(x)</code>，他就是针对输入<code>x</code>的预测标签。</li><li><strong>样本数</strong>：<code>m</code>，他就是我们每次输入多少样本进行计算，比如：某一次输入<code>5</code>组<code>x</code>，得到<code>5</code>个预测结果，这里的<code>m=5</code>.</li></ul><h3 id="3-02-绝对值损失函数"><a href="#3-02-绝对值损失函数" class="headerlink" title="3.02. 绝对值损失函数"></a>3.02. 绝对值损失函数</h3><blockquote><p>其实就是简单的计算 真实值 与 预测值 之间的绝对值距离而已。</p></blockquote><p><strong>公式</strong>：</p><p><img src="https://i.loli.net/2021/04/09/5Pc8m176fTxRVEw.png"></p><p><strong>解释</strong>：</p><ul><li><code>J(y,f(x))</code> 的意思就是，这个损失函数的参数是：真是标签<code>y</code> 与 预测数据<code>f(x)</code>  。</li><li><code>J(w,b)​</code> 的意思是，这个损失函数的目的是优化参数 <code>w</code> 与 <code>b</code> 。这里的<code>w</code>，<code>b</code>其实就是系数的矩阵形式。</li><li>后边具体的计算公式就是：输入有<code>m</code>个样本，计算出这<code>m</code>个样本的距离绝对值和，然后再求均值。</li></ul><h3 id="3-03-均方差损失函数"><a href="#3-03-均方差损失函数" class="headerlink" title="3.03 均方差损失函数"></a>3.03 均方差损失函数</h3><blockquote><p>就是将上边式子的绝对值换成平方就好了。</p></blockquote><p><strong>公式：</strong></p><p><img src="https://i.loli.net/2021/04/09/zKNdaCFf1GR2mk4.png"></p><p><strong>解释：</strong></p><ul><li>这里只是将绝对值换成了平方，除以<code>m</code>换成了除以<code>2m</code>。</li></ul><h3 id="3-04-交叉熵损失函数"><a href="#3-04-交叉熵损失函数" class="headerlink" title="3.04 交叉熵损失函数"></a>3.04 交叉熵损失函数</h3><blockquote><p>这个就比较麻烦了，交叉熵损失函数一般用于解决分类问题。</p></blockquote><p><strong>标签</strong>：</p><p>在通常的分类问题中，标签<code>y</code>的取值一般只有 <code>0</code> 或 <code>1</code> 。 </p><blockquote><p>1 表示是当前类别， 0 表示不是当前类别。</p></blockquote><p><strong>公式：</strong></p><p><img src="https://i.loli.net/2021/04/09/2KacujpOY18Z7EW.png"></p><p><strong>解释：</strong></p><ul><li>上边说了，<code>y</code> 与 <code>f(x)</code> 都只能取 <code>1</code> 与 <code>0</code> 中的一种可能性。所以，上述公式的效果就是：</li><li><strong>如果 y与 f(x) 相同，则 J = 0</strong>.</li></ul><blockquote><p>你带入 <code>y=1 , f(x)=1 </code>试试就知道了。</p></blockquote><ul><li><strong>如果 y与 f(x) 不同，则 J = 无穷大</strong>.</li></ul><blockquote><p>你带入 <code>y=1 , f(x)=0 </code>试试就知道了。</p></blockquote><h3 id="3-05-总结"><a href="#3-05-总结" class="headerlink" title="3.05 总结"></a>3.05 总结</h3><p>到这里你已经学习了三种常见的损失函数。</p><p><strong>此时你应该有一个明确的知识点就是：</strong></p><ul><li><strong>损失函数是用来计算真实值与预测值之间距离的。</strong></li><li><strong>当损失函数的值越小就代表着真实值与预测值之间的距离就越小，也就意味着预测的越准。</strong></li></ul><h2 id="4-梯度下降"><a href="#4-梯度下降" class="headerlink" title="4. 梯度下降"></a>4. 梯度下降</h2><blockquote><p>好了好了，上边过完理论知识，这里来一个真真正正的数学内容了，其实不难，看我慢慢分析。</p></blockquote><ul><li>上边我们提到对数学函数优化的时候，只是介绍了理论的知识。</li></ul><blockquote><p>我们知道了损失函数就是衡量预测值与真实值之间距离的公式。</p><p>并且知道，损失函数的值越小，真实值和预测值之间的距离越小，也即：预测的越准。</p></blockquote><ul><li>但是并没有带着大家深入探究如何优化。</li></ul><blockquote><p>也就是没有告诉大家怎么使得损失函数的值越来越小。</p></blockquote><p><strong>其实，这里使用的数学知识就是 ：求偏导</strong></p><h3 id="4-01-数学例子"><a href="#4-01-数学例子" class="headerlink" title="4.01. 数学例子"></a>4.01. 数学例子</h3><blockquote><p>这里以一个简单的数学例子来引入梯度下降的内容。</p></blockquote><ul><li><strong>场景引入</strong></li></ul><blockquote><p>在数学课中我们经常做的一个题型就是：已知一个函数<code>f(x)</code>的表达式，如何求出这个式子的最小值点。</p></blockquote><p>在数学题中我们经常用的方法就是：将函数<code>f(x)</code>对<code>x</code>求导，然后令导数式子为<code>0</code>，求出此时的<code>x</code>的值，即为最小值点的位置。</p><ul><li><strong>具体例子</strong></li></ul><blockquote><p>求函数 <img src="https://i.loli.net/2021/04/09/DlG9apZEqMH7wJm.png"  style="zoom:75%;" /> 的最小值点，并且求出最小值。</p></blockquote><p><strong>对函数求导</strong></p><p><img src="https://i.loli.net/2021/04/09/9mVwujlFiISzhDC.png"></p><p><strong>令导函数为0，求出此时的x</strong></p><p><img src="https://i.loli.net/2021/04/09/adloStYVUqwMC7L.png"></p><p>此时，<code>x = 3</code> 即为函数 <code>f(x)</code> 的最小值点，带入原方程 <code>f(3)= 2*9-12*3+20 = 2</code>.</p><blockquote><p>这个解题过程，想必大家都很熟悉吧。</p></blockquote><p><strong>下边就分析一下这个过程的数学原理了</strong></p><h3 id="4-02-数学例子原理"><a href="#4-02-数学例子原理" class="headerlink" title="4.02. 数学例子原理"></a>4.02. 数学例子原理</h3><blockquote><p>梯度就是导数。</p></blockquote><p>针对上边提到的方程的最小值求解，其实就是求出其梯度（导数）为<code>0</code>的位置，就是其最低点的位置。具体看下图：</p><ul><li>方程  <img src="https://i.loli.net/2021/04/09/WZgIfh6bQCKxEeu.png">  图像如下：</li></ul><p><img src="https://i.loli.net/2021/04/08/6r1CtSWshHFw8nX.png"></p><blockquote><p>从图中可以看出，方程在不同位置的导数方向是不同的，只有在最低点的位置，导数为<code>0</code>，所以可以用导数为<code>0</code>的位置求出最低点。</p></blockquote><p><strong>上边举的例子是一个比较简单的例子，方程中只有一个未知数，但是在真实情况中，往往一个方程有很多未知数。</strong></p><ul><li>比如：<img src="https://i.loli.net/2021/04/09/MQ89EwdszXVG1j4.png">​</li></ul><blockquote><p>此时需要做的事情就是针对每一个变量求偏导，<strong>求出该方程针对每个变量的梯度方向</strong> （梯度方向就是数据变小的方向）。</p></blockquote><p><strong>于是，在方程的每个点上，都有多个梯度方向，最终将这多个方向合并，形成这个点的最终梯度方向 （数据变小的方向）</strong></p><p><img src="https://i.loli.net/2021/04/08/2ejDRG3c8dzqs7P.png"></p><blockquote><p>如图，方程有两个变量<code>x</code>,<code>y</code>，于是在A点针对两个变量求偏导就可以得到各自的梯度方向（两个红色箭头的方向）。</p><p>然后，将两个梯度进行合并，得到最终的梯度方向<code>Z</code> 。<strong>Z方向就是方程在A点数据变小的方向了</strong>。</p></blockquote><h3 id="4-03-完整例子"><a href="#4-03-完整例子" class="headerlink" title="4.03. 完整例子"></a>4.03. 完整例子</h3><blockquote><p>上边讲完原理，这里就举出一个例子，带着大家走一遍梯度下降找最小值的过程。</p></blockquote><p>假设此时的方程已知，并且根据方程绘制出的图像如下。</p><p><img src="https://i.loli.net/2021/04/08/zNKWvU3pgBhdwLi.png"></p><ul><li>刚开始我们位于A点：</li></ul><blockquote><p>1、在A点处针对方程的各个变量求出偏导，于是便可以得到方程针对各个方向的梯度方向。</p><p>2、将A点处各个方向的梯度方向进行合并，形成最终的梯度方向。</p><p>3、最终的梯度方向就是AB方向。</p><p>4、于是向着AB方向走出一段距离，走到了B点。</p></blockquote><ul><li>到达B点： （思路同上）</li></ul><blockquote><p>1、求出B点处各个方向的梯度方向，然后合并所有梯度方向，得到最终的B点处梯度方向 BC。</p><p>2、于是沿着BC方向，走出一段距离，到达C点。</p></blockquote><ul><li>…重复上述过程：</li></ul><blockquote><p>到达某个点之后，求出各方向的偏导数，然后合并得到最终的梯度方向。</p><p>然后沿着合并后的梯度方向走出一段距离到达下一个点。</p><p>然后在一直重复……</p></blockquote><ul><li>到达K点：</li></ul><blockquote><p>K点就是最终的点，这就是优化得到的最重点。</p></blockquote><p><strong>这就是整个找最小点的可视化过程，但是其中提到更新的数学细节并没有提到，所以下边提一下用到的数学更新公式吧</strong></p><h3 id="4-04-更新公式"><a href="#4-04-更新公式" class="headerlink" title="4.04. 更新公式"></a>4.04. 更新公式</h3><blockquote><p>一般我们梯度下降更新的数据只有函数的系数，然后函数的系数可以分为两类：权重（W）+ 偏差（b）</p><p>所以，更新的时候也就针对这两个参数就好了。</p></blockquote><p><strong>变量定义：</strong></p><ul><li><code>W</code> ： 方程的权重。 （可以简单理解为方程变量前面的系数）</li><li><code>b</code> ：方程的偏差。 （可以简单理解为方程中的常数）</li></ul><blockquote><p>比如：<img src="https://i.loli.net/2021/04/09/754KhbwLsFrWMuI.png"> 中，<code>2 , 1</code>就是权重，<code>3</code>就是偏差。</p></blockquote><p><strong>公式：</strong></p><ul><li>更新权重<code>W</code>：<img src="https://i.loli.net/2021/04/09/rP23dmUkzvafX9h.png">.</li></ul><blockquote><p>原始点的权重是 <img src="https://i.loli.net/2021/04/09/XrEqubYQlRvoDpA.png">，原始点此时针对<code>W</code>的梯度方向是<img src="https://i.loli.net/2021/04/09/Pat4Q6iN9d2MAKk.png">.</p><p><code>α</code> 就是一段距离长度（它就是我们上文一直提到的走一段距离）。</p><p>所以 <img src="https://i.loli.net/2021/04/09/7bVpz3hHmOPsZYu.png"> 表达的含义就是沿着 <code>W</code>的梯度走一段长度为 <code>α</code> 的距离。</p><p>然后 <strong>新的<code>W</code></strong> 就是 <strong>旧的<code>W</code></strong> 减去那一段<strong>方向长度</strong>。</p></blockquote><ul><li>更新偏差：<img src="https://i.loli.net/2021/04/09/BSlJLerounPHUdG.png">.</li></ul><blockquote><p>原理同 <code>W</code> .</p></blockquote><p><strong>这就是更新参数的整个梯度下降过程了。</strong></p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><p>到目前为止，基础的人工智能知识已经基本讲完了，这个时候我们再来仔细品味这句话。</p><p><strong>针对特定的任务，找出合适的数学表达式，然后一直优化表达式，直到这个表达式可以用来预测未来</strong>。</p><p>或许你就会有不一样的体会了。</p><p>ok，下一节就讲一讲Pytorch的基础使用，然后就是最终的手写体数字识别任务了。</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-目标检测YOLOV1</title>
      <link href="2021/03/14/lun-wen-jing-du-mu-biao-jian-ce-yolov1/"/>
      <url>2021/03/14/lun-wen-jing-du-mu-biao-jian-ce-yolov1/</url>
      
        <content type="html"><![CDATA[<h2 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h2><blockquote><p>其中绿线是我绘制的图像划分网格。</p><p>这里的loss是我训练的 0.77 ，由于损失函数是我自己写的，所以可能跟大家的不太一样，这个不重要，重要的是学习思路。</p></blockquote><p><img src="https://i.loli.net/2021/03/14/jDaYKel3G51zviX.png"></p><p><img src="https://i.loli.net/2021/03/14/BhnqzdSl1C5ZMHa.png"></p><h2 id="重点提示"><a href="#重点提示" class="headerlink" title="重点提示"></a>重点提示</h2><p><strong><code>yolov1</code>是一个目标检测的算法，他是一阶段的检测算法。</strong></p><blockquote><p>一阶段（<code>one-stage</code>）：检测物体的同时进行分类。（代表论文：<code>yolov1 - yolov5</code>）</p><p>二阶段（<code>two-stage</code>）：先检测出物体，再进行分类。（代表论文：<code>rcnn，fast-rcnn</code>）</p></blockquote><p><strong>重点要理解yolov1的数据特征标注方式。</strong></p><blockquote><p>只有理解了数据特征的标注方式才可以理解他为什么可以起作用。</p></blockquote><h2 id="论文剖析"><a href="#论文剖析" class="headerlink" title="论文剖析"></a>论文剖析</h2><blockquote><p>1、理解<code>VOC</code>数据集的数据形式。</p><p>2、从<code>VOC</code>数据集中提取出标注好的数据特征。</p><p>3、<code>yolov1</code>的数据组织。</p><p>4、<code>yolov1</code>的算法模型。</p><p>5、<code>yolov1</code>的准确率评估方式<code>（IOU）</code>。</p><p>6、<code>yolov1</code>的损失函数。</p></blockquote><h3 id="理解VOC数据集"><a href="#理解VOC数据集" class="headerlink" title="理解VOC数据集"></a>理解VOC数据集</h3><blockquote><p>首先需要知道我们使用的数据集的形式，因为每一个数据集的特征标注以及组织方式都不同。</p></blockquote><p>我们可以去官网下载voc的数据集，这里使用的是<code>voc2012</code>数据集。</p><p><a href="https://pjreddie.com/projects/pascal-voc-dataset-mirror/">VOC数据集镜像网站</a>.  下载<code>voc2012</code>的<code>Train/Validation Data (1.9 GB)</code>。</p><p>数据集下载之后解压出来是这样子：</p><blockquote><p>每个文件夹存放的啥都标注好了，我们这里用不到那么多。</p><p>我们只用<strong>jpg原图</strong>，以及每个原图中<strong>目标的位置</strong>即可。（下边图片中画红框的两个文件夹）</p></blockquote><p><img src="https://i.loli.net/2021/03/12/CQmRbu1VeDwox7X.png" alt="image-20210312134753503"></p><p><strong>但是我们发现，Annotations文件夹中的目标位置信息是存放在xml中，所以我们往下分析一个xml文件看看。</strong></p><blockquote><p><code>&lt;filename&gt;</code> : 表示这个文件是对应于哪一个 <code>jpg</code> 图片的。</p><p><code>&lt;size&gt;</code>：表示对应的<code> jpg</code> 图片大小。</p><p><code>&lt;object&gt;</code>：就是这个图片中的目标在图片中的信息。包括：目标名字，是否难识别，以及目标在整个图片中的坐标位置。（有几个 object 就是有几个目标）</p></blockquote><p><img src="https://i.loli.net/2021/03/12/F7IPkbuAGtEi853.png" alt="image-20210312135907293"></p><h3 id="提取目标初始数据"><a href="#提取目标初始数据" class="headerlink" title="提取目标初始数据"></a>提取目标初始数据</h3><blockquote><p>上边我们分析出每个图片中有什么目标都是存储在<code>xml</code>文件中的，所以我们需要将<code>xml</code>文件的目标与类别数据提取出来，以便我们使用。</p></blockquote><p><strong>思路：</strong></p><ul><li><p>1、使用库 <code>xml.etree.ElementTree</code> 读取xml格式的文件，从中提取出每一个xml文件中的所有<code>&lt;ojgect&gt;</code>标签数据（个数就是目标的数量）。</p></li><li><p>2、将<code>&lt;object&gt;</code>标签提取出 <code>类别</code>、<code>xmin</code>、<code>ymin</code>、<code>xmax</code>、<code>ymax</code> ，并且将其归一化为 <code>类别、x、y、w、h</code>。</p></li></ul><blockquote><p>归一化就是根据从目标中提取出的 <code>xmin</code>、<code>ymin</code>、<code>xmax</code>、<code>ymax</code> 得到目标的宽高，分别除以整个图片的宽高。</p><p><code>x</code>：目标的中心位置<code>x</code>坐标。 <code>y</code>：目标的中心位置<code>y</code>坐标。 <code>w</code>：目标的宽度，<code>h</code>：目标的高度。</p></blockquote><ul><li>3、然后将归一化的数据按照上面的格式，整理为labels文件。</li></ul><blockquote><p>每一个<code>labels</code>文件对应于一个图片，<code>labels</code>文件中的每一行就是这个图片中的一个目标的 <code>类别、x、y、w、h</code> 数据（一个图片有几个目标，对应的labels文件就有几行）。</p></blockquote><p><strong>例子：</strong></p><blockquote><p>针对如下xml文件，可以得知：</p><ul><li>对应的<code>jpg</code>图片是 <code>2007_000042.jpg</code>，并且图片的大小是 <code>500*335</code> 的三色图（这里的图片大小就是用来归一化的）。</li><li>含有两个<code>&lt;object&gt;</code>标签，所以这个图片中有两个目标，并且目标的类别、位置坐标可以根据<code>name</code>、<code>xmin</code>、<code>ymin</code>、<code>xmax</code>、<code>ymax</code> 得到。</li></ul></blockquote><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">annotation</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">folder</span>&gt;</span>VOC2012<span class="tag">&lt;/<span class="name">folder</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">filename</span>&gt;</span>2007_000042.jpg<span class="tag">&lt;/<span class="name">filename</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">source</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">database</span>&gt;</span>The VOC2007 Database<span class="tag">&lt;/<span class="name">database</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">annotation</span>&gt;</span>PASCAL VOC2007<span class="tag">&lt;/<span class="name">annotation</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">image</span>&gt;</span>flickr<span class="tag">&lt;/<span class="name">image</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">width</span>&gt;</span>500<span class="tag">&lt;/<span class="name">width</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">height</span>&gt;</span>335<span class="tag">&lt;/<span class="name">height</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">depth</span>&gt;</span>3<span class="tag">&lt;/<span class="name">depth</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">segmented</span>&gt;</span>1<span class="tag">&lt;/<span class="name">segmented</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">object</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>train<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">pose</span>&gt;</span>Unspecified<span class="tag">&lt;/<span class="name">pose</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">truncated</span>&gt;</span>1<span class="tag">&lt;/<span class="name">truncated</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">difficult</span>&gt;</span>0<span class="tag">&lt;/<span class="name">difficult</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bndbox</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">xmin</span>&gt;</span>263<span class="tag">&lt;/<span class="name">xmin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ymin</span>&gt;</span>32<span class="tag">&lt;/<span class="name">ymin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">xmax</span>&gt;</span>500<span class="tag">&lt;/<span class="name">xmax</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ymax</span>&gt;</span>295<span class="tag">&lt;/<span class="name">ymax</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bndbox</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">object</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">object</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>train<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">pose</span>&gt;</span>Unspecified<span class="tag">&lt;/<span class="name">pose</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">truncated</span>&gt;</span>1<span class="tag">&lt;/<span class="name">truncated</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">difficult</span>&gt;</span>0<span class="tag">&lt;/<span class="name">difficult</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bndbox</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">xmin</span>&gt;</span>1<span class="tag">&lt;/<span class="name">xmin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ymin</span>&gt;</span>36<span class="tag">&lt;/<span class="name">ymin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">xmax</span>&gt;</span>235<span class="tag">&lt;/<span class="name">xmax</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ymax</span>&gt;</span>299<span class="tag">&lt;/<span class="name">ymax</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bndbox</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">object</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">annotation</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>大致如下：绿色框 与 蓝色框 分别是两个目标。</p></blockquote><p><img src="https://i.loli.net/2021/03/14/1hurCQsf4MEKSdA.png" alt="image-20210314151928675"></p><blockquote><p>使用xml文件中已有数据，得到 labels文件如下：</p><p>其中每一行是一个物体，每行的数据表示的意义是： <code>类别</code>,<code>x</code>,<code>y</code>,<code>w</code>,<code>h</code> . （数据都是归一化过了）</p></blockquote><p><img src="https://i.loli.net/2021/03/14/BhOMtuIl6RgdroW.png" alt="image-20210314202842390"></p><p><strong>所以，这个就是最初的labels文件的形式。</strong></p><blockquote><p>下一步就是将这个初始labels文件数据形式，组织成可以 直接与对应图片运行 的数据形式。</p></blockquote><h3 id="YOLOV1的数据组织"><a href="#YOLOV1的数据组织" class="headerlink" title="YOLOV1的数据组织"></a>YOLOV1的数据组织</h3><blockquote><p>其实yolo的思想可以用一句话来代替：<strong>将一个张图片划分网格(通常是<code>7*7</code>)，然后找目标的中心落在那个网格中(得到目标中心点坐标)，并且以中心点坐标为参考找出目标边框的宽与高。</strong></p></blockquote><h4 id="将图片进行网格划分"><a href="#将图片进行网格划分" class="headerlink" title="将图片进行网格划分"></a>将图片进行网格划分</h4><blockquote><p>如图，针对图片进行 <code>7*7</code> 的网格划分。</p></blockquote><p><img src="https://i.loli.net/2021/03/14/GhbtKw5rQdplToB.png" alt="image-20210314160519608"></p><h4 id="找目标物体中心落所在的网格"><a href="#找目标物体中心落所在的网格" class="headerlink" title="找目标物体中心落所在的网格"></a>找目标物体中心落所在的网格</h4><blockquote><p>所以这个图片中的两个目标 <code>cat</code> 与 <code>person</code> 的中心点分别落在网格中的<code>（5，1）</code> 与<code>（3，4）</code>两个位置，并且可以知道这个中心点相对于当前网格的坐标（就是紫色框表示的内容）。</p></blockquote><p><img src="https://i.loli.net/2021/03/14/9zEq2IeTNbkU87l.png" alt="image-20210314162931173"></p><h4 id="目标物体的宽高"><a href="#目标物体的宽高" class="headerlink" title="目标物体的宽高"></a>目标物体的宽高</h4><blockquote><p>在物体中心点找出之后，以中心点为坐标找出边框的宽与高即可。</p></blockquote><p><strong>经过上边的分析，我们可以发现</strong>：想要确定一个物体，只要知道它的中心点坐标，以及相对于中心点坐标的物体宽高即可。</p><p><strong>所以</strong>：当我们的模型拿到一张图片之后</p><ul><li>首先，将图片进行网格划分。</li><li>然后，判断每一个小网格中是否有物体。</li><li>如果预测有物体就预测出物体相对于本网格的坐标，以及相对于本坐标的物体宽高。</li></ul><h4 id="labels的组织方式"><a href="#labels的组织方式" class="headerlink" title="labels的组织方式"></a>labels的组织方式</h4><blockquote><p>labels的数据都是来自上边xml中提取的数据。</p></blockquote><p>经过上边yolo运作流程的讲解，可以得知labels数据需要 <strong>针对每一个小网格</strong> 组织出：<code>相对于当前网格中心点的坐标</code>，<code>宽高</code>，<code>预测概率</code>，<code>目标类别</code>。</p><p><strong>其中</strong>：</p><ul><li><strong>预测概率</strong>的值是 1或0，有目标的时候预测值是1，没目标的时候预测值是0。</li><li>这里用20个<strong>类别</strong>，每一个网格预测的目标是什么类别，则对应的类别数字为1，否则为0 （细节见下图）。</li></ul><p><strong>注意：</strong>由于每一个网格中可能会有多个目标的中心点，所以这里的labels组织的时候，将每个格子预测两个中心点。（细节见下图）</p><blockquote><p>这个图是所有网格的数据形式。数据长度为30.</p><p>**这个图中的所有数据都可以根据 上文从xml中提取的数据得到。  **</p></blockquote><p><img src="https://i.loli.net/2021/03/14/lNbTdsS67UqA2Gc.png" alt="image-20210314173554406"></p><p>由此可知，<strong>每个网格</strong>的labels是由<strong>长度为30</strong>的上述数据组成的；因为我们的图片划分为<code>7*7</code>个网格，所以就是有<code>7*7</code>个长度为30的数据组成整个图片的lables。即整张图片的labels数据形式为：<code>7*7*30</code>。labels数据矩阵如下图所示。</p><p><img src="https://i.loli.net/2021/03/14/6TNiGgEQ9IFcpb4.png" alt="image-20210314201431371"></p><blockquote><p>所以，我们输入网络的数据就是图片转为tensor的数据，<strong>inputs维度为</strong>：[batchsize，3，448，448].</p><p>网络的输入<strong>labels维度为</strong>：[batchsize，30，7，7]. 就是上边的数据矩阵。</p><p><strong>网络的输出</strong>：[batchsize，30，7，7].</p></blockquote><p><strong>ok，上边的数据组织完成，那么接下来就是将组织好的 inputs 与 labels 送入网络训练即可。</strong></p><h3 id="YOLOV1模型"><a href="#YOLOV1模型" class="headerlink" title="YOLOV1模型"></a>YOLOV1模型</h3><ul><li>网络有24个卷积层，然后是2个全连接层，简化了1×1还原层，由3×3个卷积层组成。</li><li>（原文使用的是imageNet作为预处理模型，然后后边的输出重写成所需要的输出。）</li><li>我这里使用的是基于resnet的预处理模型。</li></ul><img src="https://i.loli.net/2021/03/12/TXMDNsHLhSrx38d.png" style="zoom:80%;" /><h3 id="评估标准IOU"><a href="#评估标准IOU" class="headerlink" title="评估标准IOU"></a>评估标准IOU</h3><blockquote><p>IOU就是交并比，因为原来有一个正确的目标边框数据，此时我们预测一个边框数据之后，计算出两个边框相交的面积，在计算出相并的面积，然后求出比值，就是交并比。</p></blockquote><p><img src="https://i.loli.net/2021/03/14/YEBdAseGQSmcL9q.png" alt="image-20210314205253367"></p><p><strong>交并比越 大 ，说明两个框子越相似，说明预测结果越好。最大 IOU=1 ，就是预测框与真实框重合。</strong></p><p><strong>交并比越 小 ，说明两个框子越不相似，说明预测结果越差。最小 IOU=0 ，就是预测框与真实框没有一点相交的地方。</strong></p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><blockquote><p>三部分组成。</p></blockquote><p><img src="https://i.loli.net/2021/03/14/V819RSagWlhybFf.png" alt="image-20210314210747590"></p>]]></content>
      
      
      <categories>
          
          <category> 目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文精读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>001-深度学习Pytorch环境搭建(Anaconda , PyCharm导入)</title>
      <link href="2021/03/03/shen-du-xue-xi-pytorch-huan-jing-da-jian/"/>
      <url>2021/03/03/shen-du-xue-xi-pytorch-huan-jing-da-jian/</url>
      
        <content type="html"><![CDATA[<h1 id="001-深度学习Pytorch环境搭建-Anaconda-PyCharm导入"><a href="#001-深度学习Pytorch环境搭建-Anaconda-PyCharm导入" class="headerlink" title="001-深度学习Pytorch环境搭建(Anaconda , PyCharm导入)"></a>001-深度学习Pytorch环境搭建(Anaconda , PyCharm导入)</h1><p>在开始搭建之前我们先说一下<strong>本次主要安装的东西有哪些</strong>。</p><ul><li><strong>anaconda 3</strong>：第三方包管理软件。</li></ul><blockquote><p>这个玩意可以看作是一个大仓库，他里边含有很多Python的第三方开发库（也就是别人发布的，他收集起来管理）。安装好这个软件之后我们便可以使用这个大仓库来安装一些我们需要的包 （人工智能需要用的包也可以使用这个来装）。</p><p>同时，这个软件也可以管理我们的开发环境，让我们的环境看起来更加的简洁明了。</p></blockquote><ul><li><strong>安装Pytorch</strong>：深度学习使用的第三方包。</li></ul><blockquote><p>因为进行人工智能的开发需要进行一系列的求梯度（求导），正向传播，反向传播等等操作，如果每次都是人为的编写，有点太过于复杂了，所以Pytorch就可以理解为是将这些操作封装好的一个第三方库。我们安装好来使用即可。</p></blockquote><h2 id="1-安装anaconda"><a href="#1-安装anaconda" class="headerlink" title="1. 安装anaconda"></a>1. 安装anaconda</h2><blockquote><p>安装包管理软件anaconda，用来管理我们人工智能所需要的包。</p></blockquote><h3 id="1-01-下载anaconda"><a href="#1-01-下载anaconda" class="headerlink" title="1.01 下载anaconda"></a>1.01 下载anaconda</h3><blockquote><p>下载主要通过2种方式：</p><ul><li>官网：<strong>不推荐</strong>，慢到爆炸。</li><li>清华镜像：<strong>推荐</strong>，记得搭配第三方下载软件（不然浏览器下载也挺慢的），比如：迅雷。</li></ul></blockquote><h4 id="1-01-001-官方下载（不推荐）"><a href="#1-01-001-官方下载（不推荐）" class="headerlink" title="1.01.001 官方下载（不推荐）"></a>1.01.001 官方下载（不推荐）</h4><blockquote><p>这个方式<strong>不推荐</strong>，因为官网是外网，速度挺慢的，但是还是有必要介绍一下官网。</p></blockquote><p><strong>官网下载地址</strong>：<a href="https://www.anaconda.com/products/individual">anaconda官方下载地址</a></p><blockquote><p>点进去之后，点击 <code>Download</code> 就会跳转到版本选择页面，选择对应的版本即可。</p></blockquote><img src="https://i.loli.net/2021/02/27/Ox5ZscCQgpNEHbT.png" alt="image-20210227204113333" style="zoom:60%;" /><blockquote><p>选择对应的版本，点击下载即可。</p></blockquote><img src="https://i.loli.net/2021/02/27/gWCcGb1t9EhBOmU.png" alt="image-20210227204227111" style="zoom:60%;" /><h4 id="1-01-002-清华镜像-推荐"><a href="#1-01-002-清华镜像-推荐" class="headerlink" title="1.01.002 清华镜像(推荐)"></a>1.01.002 清华镜像(推荐)</h4><blockquote><p>anaconda的服务器是在国外，所以直接去它的官网下载，速度会很慢。</p><p>但是，我们国内有一些网站是专门用来收集软件的，<code>清华镜像源</code> 就是清华官方的一个网站，他里边收集了anaconda的安装包，我们可以去他的网站下载，服务器在国内所以速度还算不错。</p></blockquote><p><strong>清华镜像源下载地址</strong>：<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/?C=M&O=D">清华镜像源下载地址</a></p><blockquote><p>进入之后，找到对应的版本 <code>Anaconda3-2020.02-Windows-x86_64.exe</code> ，点击下载即可。</p></blockquote><img src="https://i.loli.net/2021/02/27/Nyeoc7fuRKB9XnQ.png" alt="image-20210227205011879" style="zoom:60%;" /><p><strong>tips</strong>：可以把下载链接赋值入迅雷，下载更快。</p><h3 id="1-02-安装anaconda"><a href="#1-02-安装anaconda" class="headerlink" title="1.02 安装anaconda"></a>1.02 安装anaconda</h3><blockquote><p>下载好了，就安装吧。</p></blockquote><h4 id="1-02-001-安装前提示"><a href="#1-02-001-安装前提示" class="headerlink" title="1.02.001 安装前提示"></a>1.02.001 安装前提示</h4><ul><li>千万别装 <code>C </code>盘。</li><li>安装的位置文件夹路径<strong>千万别</strong>有 <code>空格</code> 以及 <code>中文</code>。</li></ul><h4 id="1-02-002-安装"><a href="#1-02-002-安装" class="headerlink" title="1.02.002 安装"></a>1.02.002 安装</h4><ul><li><strong>step1</strong>：新建一个文件夹，用于安装anaconda。</li></ul><blockquote><p>我这里是在 <code>E</code> 盘下新建一个 <code>Anaconda</code> 文件夹。  </p></blockquote><img src="https://i.loli.net/2021/02/27/vM3tDyS1fIrwb7T.png" alt="image-20210227205947045" style="zoom:70%;" /><ul><li><strong>step2</strong>：双击下载好的软件，进行安装。</li></ul><blockquote><p>双击 <code>Anaconda3-2020.02-Windows-x86_64.exe</code>，等他加载，进行安装。</p></blockquote><img src="https://i.loli.net/2021/02/27/2fxcarQP1ZpJven.png" alt="image-20210227210109455" style="zoom:80%;" /><blockquote><p>点击 <code>next</code>.</p></blockquote><img src="https://i.loli.net/2021/02/27/xuegtKU3JqzHv8d.png" alt="image-20210227210210196" style="zoom:80%;" /><blockquote><p>点击 <code>I Agree</code>。</p></blockquote><img src="https://i.loli.net/2021/02/27/U7FA9kyNOPZEahM.png" alt="image-20210227210302458" style="zoom:80%;" /><blockquote><p>选中 <code>All User</code> , 点击 <code>Next</code>。</p></blockquote><img src="https://i.loli.net/2021/02/27/lpG2PwSjAkIZoW8.png" alt="image-20210227210426130" style="zoom:80%;" /><blockquote><p>如果蹦出类似一下的框框，选择 <code>是</code> 即可。</p></blockquote><img src="https://i.loli.net/2021/02/27/xIc587oUiJT6dtP.png" alt="image-20210227210517121" style="zoom:80%;" /><ul><li><strong>step3</strong>：选择刚才新建的文件夹，点击 <code>Next</code>。</li></ul><blockquote><p>刚才我在 <code>E</code> 盘新建的 <code>Anaconda</code> 文件夹，我选中他就好了，你新建的啥，选中你自己的就好。（<strong>千万不要有中文与空格</strong>）</p></blockquote><img src="https://i.loli.net/2021/02/27/SYQKC6qutRh8svj.png" alt="image-20210227210822161" style="zoom:80%;" /><ul><li><strong>step4</strong>：选中添加到环境变量（<strong>一定要选</strong>），然后点击 <code>Install</code>。</li></ul><blockquote><p>等待安装。</p></blockquote><img src="https://i.loli.net/2021/02/27/9GihkHemoZUYP2N.png" alt="image-20210227211015732" style="zoom:80%;" /><blockquote><p>安装完成，点击 <code>Next</code> ，在 <code>Next</code>，</p></blockquote><img src="https://i.loli.net/2021/02/27/XA9GLZKgtJwSpiv.png" alt="image-20210227211120666" style="zoom:80%;" /><blockquote><p>去点两个勾勾，点击<code>Finish</code></p></blockquote><img src="https://i.loli.net/2021/02/27/V2iG1zUYvMd4o6q.png" alt="image-20210227211245660" style="zoom:80%;" /><ul><li><strong>step5</strong>：检查安装是否成功。</li></ul><blockquote><p>按键盘上的 <code>Win + r</code> 键，输入<code>cmd</code> 回车。</p></blockquote><img src="https://i.loli.net/2021/02/27/GUfi6K79Ejcyza1.png" alt="image-20210227211452219" style="zoom:80%;" /><blockquote><p>在出现的黑窗口中输入 <code>conda -V</code> 回车，出现版本号就是安装成功。</p></blockquote><img src="https://i.loli.net/2021/02/27/YCuSQbZrWOjTJNv.png" alt="image-20210227211707097" style="zoom:80%;" /><p><strong>安装完成。</strong></p><h3 id="1-03-切换镜像源"><a href="#1-03-切换镜像源" class="headerlink" title="1.03 切换镜像源"></a>1.03 切换镜像源</h3><blockquote><p>首先需要弄明白什么是切换镜像源，为什么要切换？</p></blockquote><h4 id="1-03-001-镜像源是啥"><a href="#1-03-001-镜像源是啥" class="headerlink" title="1.03.001 镜像源是啥"></a>1.03.001 镜像源是啥</h4><p>刚才我们说了，anaconda是一个大仓库，他里边有很多第三方开发库，但是不幸的是anaconda服务器在国外，如果直接使用anaconda下载第三方库的话，速度会很慢，速度慢到甚至会网络超时从而安装失败。</p><p>所以，我们将anaconda的<strong>下载地址切换为我们国内的服务器</strong>（称之为 镜像源），这样子使用anaconda下载的时候，就不会访问外国服务器下载了。</p><h4 id="1-03-002-切换镜像源"><a href="#1-03-002-切换镜像源" class="headerlink" title="1.03.002 切换镜像源"></a>1.03.002 切换镜像源</h4><ul><li><strong>step1</strong>：在黑窗口输入 <code>conda config --set show_channel_urls yes</code>  并且回车。</li></ul><blockquote><p>这一步的意思就是：我们输入命令，黑窗口会显示我们命令执行的情况。如果不设置，就看不到效果。</p></blockquote><img src="https://i.loli.net/2021/02/27/GEjNprSwYJ7RI1m.png" alt="image-20210227213325791" style="zoom:80%;" /><ul><li><strong>step2</strong>：在黑窗口后输入 <code>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ </code> 并且回车。</li></ul><blockquote><p>这一步就是添加清华镜像源。</p></blockquote><img src="https://i.loli.net/2021/02/27/PhtyfNa3udvkUoG.png" alt="image-20210227213238696" style="zoom:80%;" /><ul><li><strong>step3</strong>：输入 <code>conda config --show channels</code> 并且回车。</li></ul><blockquote><p>看到以下的输出，就是成功。</p></blockquote><img src="https://i.loli.net/2021/02/27/WpqcCmjdUgyBFPz.png" alt="image-20210227213150873" style="zoom:80%;" /><h2 id="2-创建Pytorch环境"><a href="#2-创建Pytorch环境" class="headerlink" title="2. 创建Pytorch环境"></a>2. 创建Pytorch环境</h2><blockquote><p>上边已经安装好了anaconda，并且我们也知道anaconda是一个包管理工具，它可以用来管理我们的工作环境。</p><p>然后下边就使用anaconda来创建一下我们的Pytorch工作环境。</p></blockquote><ul><li><strong>step1</strong>：将<code>dos</code>路径进入到<code>anaconda</code>安装路径下的<code>Scripts</code>文件夹下。</li></ul><blockquote><p>首先打开<code>anaconda</code>安装路径下的<code>Scripts</code>文件夹。（我的安装在 <code>E:\Anaconda</code>，所以进入<code>E:\Anaconda\Scripts</code>）</p></blockquote><img src="https://i.loli.net/2021/03/02/ct4uBUMm3o7lTZn.png" alt="image-20210302141535138" style="zoom:80%;" /><blockquote><p>点击路径后边空白处。</p></blockquote><img src="https://i.loli.net/2021/03/02/WIXkLcYtJB9uQFT.png" alt="image-20210302141745832" style="zoom:80%;" /><blockquote><p>在路径蓝色的情况下，输入<code>cmd</code> , 回车进入 <code>dos</code>。</p></blockquote><img src="https://i.loli.net/2021/03/02/ZBG61g4ivjLnoOH.png" alt="image-20210302141907871" style="zoom:80%;" /><blockquote><p>输入<code>cmd</code>回车</p></blockquote><p><img src="https://i.loli.net/2021/03/02/Bpsm9TuUFdY8ELq.png" alt="image-20210302141943865"></p><blockquote><p>进入<code>dos</code>窗口，并且路径就是 <code>Scripts</code>文件夹所在路径。</p></blockquote><img src="https://i.loli.net/2021/03/02/JTkRjnF3aiZwGb1.png" alt="image-20210302142110605" style="zoom:80%;" /><ul><li><strong>step2</strong>：创建一个环境，用来安装Pytorch。</li></ul><blockquote><p>输入命令 <code>conda create -n pyTorchEnv python=3.7</code> ，点击回车。</p><p>其中<code>pyTorchEnv </code>是环境的名字，自己定义也可以。</p><p><code>python=3.7</code>是这个环境将使用3.7的python版本。</p></blockquote><img src="https://i.loli.net/2021/03/02/2K5plSatCoqLchQ.png" alt="image-20210302143023290" style="zoom:80%;" /><blockquote><p>这里输入 y 回车。</p></blockquote><img src="https://i.loli.net/2021/03/02/59GAhOed6QPEVSb.png" alt="image-20210302143150827" style="zoom:80%;" /><blockquote><p>下边的样子就是安装成功。</p></blockquote><img src="https://i.loli.net/2021/03/02/8K2EVhgNHp3SFja.png" alt="image-20210302143238654" style="zoom:67%;" /><ul><li><strong>step3</strong>：查看创建好的环境。</li></ul><blockquote><p>在anaconda安装路径下的envs文件夹下，会出现所有你创建的环境。</p></blockquote><p><img src="https://i.loli.net/2021/03/02/Ntuqcr2nJWPdhEg.png" alt="image-20210302143432743"></p><p><strong>这里只显示一个我们刚才安装的 pyTorchEnv 环境，但是还有一个默认的环境 base 也是存在的。</strong></p><ul><li><strong>step4</strong>：激活测试创建好的环境。</li></ul><blockquote><p>先进入创建好的环境<code>pyTorchEnv</code>文件夹中，在进入他的<code>Scripts</code>文件夹中。</p><p><strong>注意：不是 anaconda 的 Scripts 了</strong></p></blockquote><img src="https://i.loli.net/2021/03/02/dCwU1zYrptZfmEj.png" alt="image-20210302143826238" style="zoom:80%;" /><blockquote><p>点击路径后边空白处，路径变蓝色之后，输入 <code>cmd</code> 然后回车进入<code>dos</code> 中。</p></blockquote><p><img src="https://i.loli.net/2021/03/02/zu3ODBRZbCioVHl.png" alt="image-20210302144044417"></p><blockquote><p>然后输入 <code>activate pyTorchEnv</code>，激活<code>pyTorchEnv</code>环境。</p></blockquote><p><img src="https://i.loli.net/2021/03/02/J98kbv3j7oQXPet.png" alt="image-20210302144205852"></p><p><strong>激活成功就没有什么问题了</strong></p><blockquote><p>退出环境：输入<code>deactivate</code> 回车即可。</p></blockquote><h2 id="3-安装Pytorch环境"><a href="#3-安装Pytorch环境" class="headerlink" title="3. 安装Pytorch环境"></a>3. 安装Pytorch环境</h2><blockquote><p>上边已经搭建好了深度学习的环境，接下来只用在这个环境中安装深度学习pytorch需要的库即可。</p></blockquote><ul><li><strong>step1</strong>：使用 <code>dos</code> 进入 <code>pyTorchEnv</code> 环境的 <code>Scripts</code>文件夹，然后激活<code>pyTorchEnv</code>。</li></ul><blockquote><p>方法同上边，找到 <code>pyTorchEnv</code> 中的 <code>Scripts</code> 文件夹，在路径栏输入 <code>cmd</code> 回车进入<code>dos</code>。</p><p>然后使用 <code>activate pyTorchEnv</code> 激活它。</p></blockquote><img src="https://i.loli.net/2021/03/02/sA8X7jPSxnrIZGO.png" alt="image-20210302171814638" style="zoom:80%;" /><ul><li><strong>step2</strong>：到pytorch官网找到安装命令。</li></ul><blockquote><p>官网地址：<a href="https://pytorch.org/">pytorch官网</a>.</p><p>到官网往下拉，然后配置的好你的版本。 （<strong>这里先不要GPU哦。</strong>）</p></blockquote><img src="https://i.loli.net/2021/03/02/4TAFyKnLIw9WQ3t.png" alt="image-20210302191100142" style="zoom:67%;" /><ul><li><strong>step3</strong>：将复制的命令放入刚才打开的<code>dos</code>窗口，回车进行安装。</li></ul><blockquote><p>命令：<code>conda install pytorch torchvision torchaudio cpuonly -c pytorch</code> </p></blockquote><img src="https://i.loli.net/2021/03/02/reInfjwN8BOFs6D.png" alt="image-20210302191349370" style="zoom:67%;" /><blockquote><p>输入 <code>y</code>回车。</p></blockquote><img src="https://i.loli.net/2021/03/02/BcIftyparFgXNQs.png" alt="image-20210302191434824" style="zoom:60%;" /><blockquote><p>不报错就成功。</p></blockquote><img src="https://i.loli.net/2021/03/02/Qr6AMmOjNSC3d4I.png" alt="image-20210302191527567" style="zoom:50%;" /><ul><li><strong>step4</strong>：</li></ul><blockquote><p>还是进入到<code>pyTorchEnv</code>的<code>Scripts</code>中，进入<code>dos</code>，激活环境。</p></blockquote><p><img src="https://i.loli.net/2021/03/02/cbSZrnfHXp8LYwa.png" alt="image-20210302191803342"></p><blockquote><p>输入 python 回车，进入python中。</p></blockquote><img src="https://i.loli.net/2021/03/02/NxgXnLGTVBp9m8e.png" alt="image-20210302191915169" style="zoom:67%;" /><blockquote><p>导入torch包，不报错就是成功。</p></blockquote><img src="https://i.loli.net/2021/03/02/eNy7kZH92uL5w6A.png" alt="image-20210302192107486" style="zoom:67%;" /><h2 id="4-PyCharm导入Pytorch环境"><a href="#4-PyCharm导入Pytorch环境" class="headerlink" title="4. PyCharm导入Pytorch环境"></a>4. PyCharm导入Pytorch环境</h2><blockquote><p>上边创建好的环境我们需要把他导入PyCharm使用，不然只在黑窗口的话很不方便。所以这里就来演示怎么将<code>pyTorchEnv</code>环境导入PyCharm中使用。</p><p><strong>tips</strong>：</p><ul><li><p>这里我换电脑了，所以这里演示的时候，我的<code>anaconda</code>安装路径是 <code>D:\python\install\anaconda</code>。</p></li><li><p>所以，我的pyTorchEnv文件夹的路径是：<code>D:\python\install\anaconda\envs\pyTorchEnv</code>。</p></li></ul></blockquote><ul><li><strong>step1</strong>：新建PyCharm项目。</li></ul><blockquote><p>先打开PyCharm，点击新建。</p></blockquote><img src="https://i.loli.net/2021/03/02/puCknK7xJ53De9U.png" alt="image-20210302193546755" style="zoom:80%;" /><blockquote><p>进入选择 pyTorchEnv。</p></blockquote><img src="https://i.loli.net/2021/03/02/asguhyMb15oBPFf.png" alt="image-20210302193755176" style="zoom:80%;" /><blockquote><p>进入选择。</p></blockquote><img src="https://i.loli.net/2021/03/02/dhCMiaStYyQDwv1.png" alt="image-20210302193908507" style="zoom:67%;" /><blockquote><p>找到 pyTorchEnv 文件夹。</p></blockquote><img src="https://i.loli.net/2021/03/02/qrZ6djWDoltCTkA.png" alt="image-20210302194041903" style="zoom:80%;" /><blockquote><p>然后选中 pyTorchEnv 文件夹中的 python.exe 即可。</p></blockquote><img src="https://i.loli.net/2021/03/02/sfHk5pFBvbNDaeY.png" alt="image-20210302194211375" style="zoom:80%;" /><blockquote><p>在 OK。</p></blockquote><img src="https://i.loli.net/2021/03/02/rv4nHiMVg9J5oCs.png" alt="image-20210302194245154" style="zoom:80%;" /><blockquote><p>切换成功然后就可以了。</p></blockquote><img src="https://i.loli.net/2021/03/02/PgZIvjucpFiAJ78.png" alt="image-20210302194414920" style="zoom:80%;" /><p>等待之后进入到PyCharm界面。</p><ul><li><strong>step2</strong>：测试。</li></ul><blockquote><p>右键单击项目名字，新建一个 python package。然后自己起个名字。</p></blockquote><img src="https://i.loli.net/2021/03/02/MjgDQRpV984hZqf.png" alt="image-20210302194651354" style="zoom:80%;" /><blockquote><p>在 <code>__init__.py</code> 文件中输入以下代码，运行没报错就ok了。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">print( torch.cuda.is_available() )</span><br></pre></td></tr></table></figure><img src="https://i.loli.net/2021/03/02/RJUI39AVYx1eTCu.png" alt="image-20210302194938426" style="zoom:80%;" /><p><strong>OK, 搭建完成，以后的代码都是在这里敲。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python语言系列文章总结</title>
      <link href="2021/02/17/python-xi-lie-wen-zhang-fu-xi-zong-jie/"/>
      <url>2021/02/17/python-xi-lie-wen-zhang-fu-xi-zong-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="Python系列文章复习总结"><a href="#Python系列文章复习总结" class="headerlink" title="Python系列文章复习总结"></a>Python系列文章复习总结</h1><blockquote><p>终于，python文章已经更新完了，这里做出一下总结复习，相当于是整合出一个目录以便大家使用。</p></blockquote><center><b>文章的章节梳理在下文中，针对文章的视频版梳理在B站 (B站账号：小小猿笔记) 。</b></center><p>视频版Python语言知识点快速复习连接：<a href="https://www.bilibili.com/video/BV1QU4y1x7kW">Python语言程序设计基础知识点复习梳理</a></p><blockquote><p><strong>主要内容：</strong></p><ul><li>基础知识 &amp; 环境搭建。</li><li>PyCharm的基础使用。</li><li>Python的基础语法。</li><li>Python的高级语法。</li><li>Python的文件 &amp; 异常。</li><li>飞机大战。</li><li>爬虫初窥。</li></ul></blockquote><h2 id="基础知识-amp-环境搭建"><a href="#基础知识-amp-环境搭建" class="headerlink" title="基础知识 &amp; 环境搭建"></a>基础知识 &amp; 环境搭建</h2><ul><li><p>首先，既然我们来学习<code>Python</code>，那大家肯定对他有着一定的了解，但是我还是觉得有必要再介绍一下Python可以做些什么。</p></li><li><p>然后，python与C语言不太一样，由于win电脑就是C语言写的，所以C语言的程序可以直接在win电脑上执行，然后我们为了方便写代码就安装了VC6.0来敲写代码。</p></li><li><p>但是，python程序是不能直接在win电脑上运行的，所以这个时候就需要安装python的运行环境，让他来执行python程序，同样，为了敲代码方便，所以我们安装PyCharm来敲代码。</p></li></ul><p><strong>至于细节，这篇文章中就有提到。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247485130&idx=1&sn=21c753a0a70b46863f57ed0d0cd6747b&chksm=fca93188cbdeb89e2f5e83eed92ea07fde13b378e0864eb522d65b0f6090feba6405b3fe227e&token=1839830084&lang=zh_CN#rd">Python零基础入门-01-基础知识&amp;环境搭建</a> </p><h2 id="PyCharm的基础使用"><a href="#PyCharm的基础使用" class="headerlink" title="PyCharm的基础使用"></a>PyCharm的基础使用</h2><ul><li>首先，PyCharm与VC6.0都只是一个工具而已，他们的目的是用来敲代码，但是PyCharm是一款功能很强大的编译器，不像VC6.0那么简单使用。</li><li>甚至，新手都不知道怎么在PyCharm中找到敲代码的地方，所以这里的文章就会首先给你讲讲这个软件的一些简单用法，让你不至于太恐慌。</li><li>回顾，上篇文章我们提到学习python要装两个东西：python运行环境 以及 pycharm。所以在使用pycharm的时候首先就需要将python运行环境引入到pycharm中，不然你敲完的代码都没法运行的。</li><li>同样，也会教你一些简单的有用的操作。</li></ul><p><strong>至于细节，这篇文章中就有提到。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247485165&idx=1&sn=b60fb4170ef5951db79decd4f36f1c04&chksm=fca931afcbdeb8b975e9ced4f3e2943524e181623a41161fb0c386f036ab09729a8e07f64db8&token=1839830084&lang=zh_CN#rd">Python零基础入门-02-PyCharm基础使用</a> </p><h2 id="Python的基础语法"><a href="#Python的基础语法" class="headerlink" title="Python的基础语法"></a>Python的基础语法</h2><ul><li>首先，任何一门编程语言的基础语法都是差不多的，都是一些 <code>数据类型，输入输出，选择循环结构，以及函数文件</code>等等。唯一不同的就是每个编程语言怎么定义这些语法，怎么使用这些语法上，有着区别。python的定义与使用是最简单的。</li><li>然后，这一节就会带着大家了解一些基础的语法，并且掺杂着案例，让大家见一见python的简洁之处。</li></ul><p><strong>至于细节，这篇文章中就有提到。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247485249&idx=1&sn=be02f92b7b066177bd7f7b2f7805839e&chksm=fca93003cbdeb9156e6a3569f419dedc533a8a9e4bec4b2d4d61d47c020319fe4f693bb7201c&token=1839830084&lang=zh_CN#rd">Python零基础入门-03-Python基础语法</a> </p><h2 id="Python的高级语法"><a href="#Python的高级语法" class="headerlink" title="Python的高级语法"></a>Python的高级语法</h2><ul><li>首先，刚才说了每个编程语言的基础语法都大相径庭，但是他们的高级语法就各有千秋了，其他的就不说了，这里就会讲一讲python的高级语法。</li><li>然后，任何编程语言的高级语法，不管再怎么多杂，唯一不变的就是，都必须有面向对象的内容。</li><li>最后，什么是面向对象呢？ 面向对象其实是一种思想，并不是具体的语法，大家带着这个疑问就往下看文章吧。</li></ul><p><strong>至于细节，这篇文章中就有提到。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247485312&idx=1&sn=aadb0cef5258f6e4da4a5c0a1c6701e1&chksm=fca930c2cbdeb9d48f7b9c5c338f7927f2720fb23bcdf46244628dcba94e863ae71590e531be&token=1839830084&lang=zh_CN#rd">Python零基础入门-04-Python高级语法</a> </p><h2 id="Python的文件-amp-异常"><a href="#Python的文件-amp-异常" class="headerlink" title="Python的文件 &amp; 异常"></a>Python的文件 &amp; 异常</h2><ul><li>首先，前边讲基础语法的时候我们并没有讲文件，因为文件一般都是最后学的，哈哈哈哈。</li><li>文件，其实就是将用户操作完的数据给存到硬盘上，下次用户在用的时候再从文件中读取进来，以达到存档读档的效果。听我讲的热血澎湃的，其实啥也不是，就给你讲讲基础语法而已，哈哈哈哈。</li><li>异常，其实就是为了解决当程序整体出现错误的时候，不让程序崩溃，而提出的一种解决方式。</li></ul><p><strong>至于细节，这篇文章中就有提到。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247485384&idx=1&sn=d9c4ef753b1eafc58202676fd9516f21&chksm=fca9308acbdeb99c7478a719d4e10cd42c4e9a0a1cfaba186b299da92e53407c02af487c6353&token=1839830084&lang=zh_CN#rd">Python零基础入门-05-结尾(文件&amp;异常)</a> </p><h2 id="飞机大战"><a href="#飞机大战" class="headerlink" title="飞机大战"></a>飞机大战</h2><ul><li>在上次我推荐的python基础入门书 《python编程从入门到实践》 （在基础知识篇文章最后有提到怎么获取），后边有一个飞机大战的项目，但是我发现他运行不起来了，因为他的好像是基于python2的版本，然而现在都用的python3了，所以有一些语法已经跑不通了。</li><li>然后我自己按照他的思路来实现了一下飞机大战的基础功能，并且给了一些视频的讲解，让大家好理解一点。</li></ul><blockquote><p><strong>tips</strong>：pygame不要成为你的学习重点，把我的源码弄个下来跑一跑，了解一点代码以及思路就好，重点还是放在下一个爬虫的项目。</p></blockquote><p><strong>至于细节，这个视频中就有提到。</strong></p><ul><li>飞机大战B站视频链接：<a href="https://www.bilibili.com/video/BV1QU4y1x7kW?p=15">python飞机大战</a>.</li><li>飞机大战源码链接：<a href="https://github.com/xiaoxiaojiea/SharingFolder/tree/main/%E5%85%AC%E4%BC%97%E5%8F%B7%E5%88%86%E4%BA%AB/python%E7%9B%B8%E5%85%B3">公众号分享</a></li></ul><h2 id="爬虫初窥"><a href="#爬虫初窥" class="headerlink" title="爬虫初窥"></a>爬虫初窥</h2><ul><li>爬虫可以称之为一个就业方向，各大公司也是有需求的，但是要彻底学会是不太现实的，因为随着爬虫技术的崛起，反爬虫技术也在慢慢发展，现在的网站也是越来越难爬了。</li><li>但是，对于新手来说，需要学些什么，以及每个技术有什么用还是需要有一个清晰的认识的。</li><li>下边的文章以及视频可以给你一个清理明了的学习计划。</li></ul><p><strong>至于细节，这个视频中就有提到。</strong></p><ul><li>爬虫B站视频链接：<a href="https://www.bilibili.com/video/BV1Rb4y197s7">Python爬虫快速入门实战教程(附赠进阶教程)</a></li><li>爬虫源码链接：<a href="https://github.com/xiaoxiaojiea/SharingFolder/tree/main/%E5%85%AC%E4%BC%97%E5%8F%B7%E5%88%86%E4%BA%AB/python%E7%9B%B8%E5%85%B3">公众号分享</a></li></ul><p><strong>视频中提到的学习资料如下</strong>：</p><ul><li>教程获取方式：关注公众号 “ <strong>小小猿笔记</strong> ”，或者扫下边的码，然后在公众号内部回复 “ <strong>崔庆才爬虫</strong> ”，即可获取。</li><li>最新版爬虫教程链接： <a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=46&sid=460-PC_search_list-0#/sale">52讲轻松搞定网络爬虫</a> . （这个是官网，但是网上<strong>免费版</strong>的资源多的很）</li></ul><img src="https://i.loli.net/2021/02/17/NtvE2ToiLVrfWmg.jpg" alt="公众号二维码" style="zoom:80%;" />]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C语言系列文章总结</title>
      <link href="2021/02/12/c-yu-yan-xi-lie-wen-zhang-zong-jie/"/>
      <url>2021/02/12/c-yu-yan-xi-lie-wen-zhang-zong-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="C语言知识点复习梳理"><a href="#C语言知识点复习梳理" class="headerlink" title="C语言知识点复习梳理"></a>C语言知识点复习梳理</h1><blockquote><p>C语言的知识点讲完了，接下来就是做一下整理与总结，然后就会进入其他知识的学习。</p></blockquote><hr><center><b>文章的章节梳理在下文中，针对文章的视频版梳理在B站 (B站账号：小小猿笔记) 。</b></center><p>视频版C语言知识点快速复习连接：<a href="https://www.bilibili.com/video/BV1ma4y1s7YQ">C语言程序设计基础知识点复习梳理</a></p><p><strong>本文目录如下：</strong></p><blockquote><ol><li>基础知识。</li><li>顺序程序设计。</li><li>数据类型。</li><li>标准输入输出。</li><li>进制转换。</li><li>选择结构。</li><li>循环结构。</li><li>数组。</li><li>函数。</li><li>指针</li><li>结构体。</li><li>文件。</li></ol></blockquote><h2 id="0-题外话"><a href="#0-题外话" class="headerlink" title="0. 题外话"></a>0. 题外话</h2><p>这里就是说一些我觉得很基础的问题，无关紧要，但是希望可以解决你的疑惑。</p><ul><li>有什么好的C语言书籍推荐吗？</li></ul><blockquote><p>没有什么好的书，新手要么看一些好的文章，要么看视频。书籍只是用来检索知识点复习巩固的，直接看书看不下去的。至于用什么书嘛，谭浩强的就行，大学都用的这个。</p></blockquote><ul><li>学知识是在看到不懂语法怎么办。</li></ul><blockquote><p>你要明白一件事情，你学的新知识，如果实在弄不明白为什么，那就记住他，不要浪费过多的时间在这个上边，因为这些知识经历了数十载的洗礼都没有被推翻，说明他有存在的价值，只不过现在你的知识储备还不够你理解他而已。</p></blockquote><blockquote><p>不管是现实世界还是计算机世界，现有的所有知识都是人为定义出来的，然后经过大家的推敲觉得这个事情是正确的，然后就会被广泛使用。如果有一天你发现了现实世界某个知识定义的有问题，那么你也可以提出来，在学术界的审判之后，如果觉得你是正确的，那么，你就会被载入史册，并且你提出的事情也会被大家广泛使用。</p></blockquote><h2 id="1-基础知识"><a href="#1-基础知识" class="headerlink" title="1. 基础知识"></a>1. 基础知识</h2><ul><li>所谓的基础知识，就是我们之后学习C语言、甚至进入编程行业所必须具备的一些前提知识。</li></ul><blockquote><p>举一个栗子：你想认识一个经常偶遇的女生，但是你连说话的勇气都没有，那说不定下次再见到的时候，女生就会挽着别的男生的手了。</p></blockquote><p>这个例子中你去说话就是一个前提条件。编程也是这样，你不了解一些计算机的知识、你电脑上不装编译器（编译器就是敲代码的地方），那你还是不要学了，浪费时间。因为编程是在实际编写代码中成长的，而不是看书成长的。</p><p><strong>所以，需要多少基础知识呢？</strong></p><p>其实刚开始不是很多，都是一些常识的内容，十八九岁接触过电脑的同学都应该有所了解的知识而已。</p><ul><li>首先，为什么学习C语言。</li></ul><blockquote><p>C语言是IT行业人必会的一门语言，C语言可以不用，但是不能不会。当然它的优势可以在文章中找到。</p></blockquote><ul><li>其次，计算机的组成器件。</li></ul><blockquote><p>都要学编程了，不能连最基本的计算机组成都不知道吧。</p></blockquote><ul><li>最后，编译器的安装。</li></ul><blockquote><p>不仅仅是C语言要装编译器，只要你接触编程，不管学什么语言，第一步就是装编译器输出 “Hello World！”。</p></blockquote><p>但是VC6.0原版只针对win7，所以win10使用的时候需要破解，具体安装包怎么下载、安装在我文章中看。</p><p><strong>OK，所有的基础知识，都在这篇文章了。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247483826&idx=1&sn=124cd456975c66d9763b624bb2b6fd67&chksm=fca936f0cbdebfe603467b5b6edd2fc89680e854bfa72e28eec80cc46ab28a854cafa59c09d6&scene=21#wechat_redirect">C语言零基础入门—基础知识与环境搭建 </a></p><h2 id="2-顺序程序设计"><a href="#2-顺序程序设计" class="headerlink" title="2. 顺序程序设计"></a>2. 顺序程序设计</h2><ul><li>顺序程序设计，说白了就是写代码的过程，与人做一件事情的流程很像。人处理一件事情基本都是从前往后做的，代码也是一样，写在前边的代码会被先执行到，后边的代码就会被晚一点执行到。</li></ul><blockquote><p>举一个栗子：一个很经典的人物——小明同学；</p><p>小明早晨起床去学校的步骤是：穿衣服—&gt;洗漱—&gt;吃早餐—&gt;出门。</p><p>如果有一天小明睡的一脸懵逼，起床之后直接出门了，衣服没穿也没洗漱也没吃早餐，那这就是小明做事情的顺序产生了错误。</p></blockquote><p>所以，人做事情顺序有误就会闹笑话；程序执行的顺序有问题，就会出现我们常说的一个词——<strong>Bug</strong>。</p><p><strong>这一节需要学会的知识：</strong></p><ul><li>了解程序应该在哪里编写。</li></ul><blockquote><p>绝大部分编程语言编写的时候，都会有一个指定的程序开始的位置 “main”，也就是编译器执行代码的时候会到 main 中寻找代码来执行。所以我们要把我们的代码写在这个里边。</p></blockquote><ul><li>C程序运行需要的一些前提。</li></ul><blockquote><p>前一问说了，代码要写在 main 里边，那么main要放在哪里呢？文章中就会讲到。</p></blockquote><ul><li>了解编写程序的思路。</li></ul><blockquote><p>也就是说编写代码其实跟人做一件事情是一样的，只不过我们写代码的目的是让程序帮我们循环往复的做同一件事情而已。</p></blockquote><p><strong>OK，所有的知识点，都在这篇文章了。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247483839&idx=1&sn=33f6255409746d21f37ed360c25ae54c&scene=21#wechat_redirect">C语言零基础入门—顺序程序设计</a></p><h2 id="3-数据类型"><a href="#3-数据类型" class="headerlink" title="3. 数据类型"></a>3. 数据类型</h2><ul><li>现实世界中有整数、小数、分数、复数等等数据类型；这些数据类型之所以会存在，不是凭空产生的，是一些很伟大的数学家定义出来的，之所以可以被全世界用这么久并且将会一直用下去，是因为他符合<strong>人</strong>的认知并且切合实际。</li><li>编程界也可以看作是一个小世界，那么这个小世界也应该存在着一些数据类型，只不过程序中的数据类型的主体不是人，而是计算机了。由于计算机的存储方式以及存储长度的限制，C语言就会定义一些尽可能切合实际的、大家认可的数据类型来供C语言编写程序过程中使用。这就是数据类型产生的原因。</li></ul><p><strong>这一节需要学会的知识：</strong></p><ul><li>C语言中的数据类型深层次的定义是什么。</li></ul><blockquote><p>数据类型 = 一类数 + 这类数可以执行的操作。</p></blockquote><ul><li>常用数据类型有哪些，以及他们占用的字节是多少。</li></ul><blockquote><p>整形int占用4字节；浮点型float占用4字节；字符型char占用1字节。</p></blockquote><p><strong>OK，所有的知识都在这篇文章了。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247483847&idx=1&sn=0db471348e25eae49082b080b6df9701&scene=21#wechat_redirect">C语言零基础入门—数据类型</a></p><h2 id="4-标准输入输出"><a href="#4-标准输入输出" class="headerlink" title="4. 标准输入输出"></a>4. 标准输入输出</h2><ul><li>经过上边的学习你应该会知道任何数据在计算机中的存放形式都是二进制的0/1串，那么当我们想要输出一个文字的时候，总不能把这些0/1串直接输出吧。这个时候就是格式化的作用了，它可以根据用户选择的格式化方式将0/1串转化为用户想要的数据形式。</li></ul><blockquote><p>举一个栗子：用户想要一串英文字符，那么用户就会规定好输出的数据是字符串格式的，此时计算机取到内存中的0/1串的时候，就会将这些0/1串转化为英文字符，然后再输出。</p></blockquote><p><strong>这一节需要学会的知识：</strong></p><ul><li>数据在计算机中的存取过程。</li></ul><blockquote><p><strong>存</strong>：将用户数据转化为二进制数据。</p></blockquote><blockquote><p><strong>取</strong>：将二进制数据转化为用户数据。</p></blockquote><ul><li>输入输出语法的学习。</li></ul><blockquote><p>pintf（）；    scanf（）；putchar（）；getchar（）。</p></blockquote><p><strong>OK，所有的知识都在这篇文章了。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247483855&idx=1&sn=6f2ec282c59f075b051740c50b98e226&scene=21#wechat_redirect">C语言零基础入门—标准输入输出</a></p><h2 id="5-进制转换"><a href="#5-进制转换" class="headerlink" title="5. 进制转换"></a>5. 进制转换</h2><ul><li>现实世界中使用的是十进制，计算机使用是二进制，于是就要学习十进制与二进制之间的转换。</li><li>在现实世界中，如果想要描述一个很大的数，我们知道用大一点的单位来描述。计算机也是一样，如果直接用二进制描述一个数据有点繁琐，所以就会产生一些较大的单位，比如：八进制，十六进制。</li></ul><blockquote><p>举一个栗子：现实世界中10000用万做单位可以描述为10万。计算机中二进制的数据 00110001 使用十六进制表示就是 31，确实简洁许多。</p></blockquote><p><strong>这一节需要学会的知识：</strong></p><ul><li>学会进制之间的转换。</li></ul><blockquote><p>十进制——二进制之间的转化。</p></blockquote><blockquote><p>二进制——八进制——十六进制之间的转换。</p></blockquote><p><strong>OK，所有的基础知识，都在这篇文章了。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247483866&idx=1&sn=473b9cac686d9e12a3f136a33d4d8b45&scene=21#wechat_redirect">C语言零基础入门——6.进制转换-1</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247483884&idx=1&sn=1f15723f2c93a8d1fbfaf9fcaf1d9bcf&scene=21#wechat_redirect">C语言零基础入门——6.进制转换-2</a></p><h2 id="6-选择结构"><a href="#6-选择结构" class="headerlink" title="6. 选择结构"></a>6. 选择结构</h2><ul><li>选择结构就是从众多数据中选择出符合需求的数据来进行下一步操作。</li></ul><blockquote><p>举一个栗子：从整个班级的成绩单中选择出 数学成绩&gt;60分的同学，这个过程就是选择结构需要做的事情。</p></blockquote><p><strong>这一节需要学会的知识：</strong></p><ul><li>选择结构的基础语法与使用：</li></ul><blockquote><p>要学会两个基本选择结构的使用：if…else 与 switch。</p></blockquote><ul><li>要学会拼接选择的条件：</li></ul><blockquote><p>比如：对于 数学成绩&gt;60，英语成绩&gt;60 。这次的选择就有两个选择条件来控制得到的结果。这两个条件之间的关系可以是多种多样的，我们需要学会按照正确的需求来拼接他们。</p></blockquote><p><strong>OK，所有的基础知识，都在这篇文章了。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247483940&idx=1&sn=db53ff88e87f2d144388e1863861120d&scene=21#wechat_redirect">C语言零基础入门—选择结构程序设计-1</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247483949&idx=1&sn=49e64f17d9a3a89d7c5284f7b4f81a76&scene=21#wechat_redirect">C语言零基础入门—选择结构程序设计-2</a></p><h2 id="7-循环结构"><a href="#7-循环结构" class="headerlink" title="7. 循环结构"></a>7. 循环结构</h2><ul><li>日常生活中有很多事情都是重复，再重复。在程序编写中也是这个样子，有一些代码或许会被重复执行成千上万遍，这个时候就可以用循环结构去代替一些重复执行的代码，只需要保留一份代码，然后令这份代码循环执行多次即可。</li></ul><blockquote><p>举一个栗子：如果需要输出100个人的姓名，经过上边学习的输出语句可能会有人想着，要不然把输出语句printf写100次就好了；当然这是一种方法，但是，太麻烦了，使用循环结构一行代码就搞定了。</p></blockquote><p><strong>这一节需要学会的知识：</strong></p><ul><li>循环结构的语法以及使用：</li></ul><blockquote><p>有三种形式的循环语句，主要记住for循环的用法。while循环理解即可，基本上百分之90的程序for都能解决。</p></blockquote><ul><li>嵌套循环要会使用：</li></ul><blockquote><p>就是在循环结构里边再放循环。</p></blockquote><ul><li>三个循环的差异以及特性：</li></ul><blockquote><p>要知道for循环可以指定循环的次数；while循环次数不确定；do…while会先循环一次在进入判断条件。</p></blockquote><ul><li>循环的中断：</li></ul><blockquote><p>循环有两种结束方式，第一种是 循环次数或者循环条件 不满足了，就停止循环了；还有一种就是强制循环的停止。</p></blockquote><p>强制停止有两种方式：<strong>break与continue</strong>。</p><p><strong>OK，所有的基础知识，都在这篇文章了。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247483968&idx=1&sn=a9db2ada7c0c3d3b5f0b3f147c07b59a&scene=21#wechat_redirect">C语言零基础入门—循环结构程序设计-1</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247483977&idx=1&sn=7adb09f602a23bceadb5c67fe31fde1e&scene=21#wechat_redirect">C语言零基础入门—循环结构程序设计-2</a></p><h2 id="8-数组"><a href="#8-数组" class="headerlink" title="8.数组"></a>8.数组</h2><ul><li>随着深入的学习你会发现数据越来越多，有的数据格式相同、并且表达的含义相同。如果可以将这些数据存放在一起统一命名，就会很方便。于是数组的概念就产生了。</li><li>数组就是一组数据的集合，并且这个数据集合是有顺序的，集合中的所有数据的数据类型都是相同的。</li></ul><blockquote><p>举一个栗子：班级内全部同学的数学成绩就可以用一个数组存放。</p></blockquote><p><strong>这一节需要学会的知识：</strong></p><ul><li>一维数组的定义与使用：</li></ul><blockquote><p>首先需要明白数组的概念，以及一维数组怎么定义以及怎么使用。</p></blockquote><ul><li>二维数组的定义与使用：</li></ul><blockquote><p>同样掌握并且理解二维数组的定义以及使用。</p></blockquote><ul><li>数组的存储原理：</li></ul><blockquote><p>要彻底明白数组在内存中的存储原理以及数组元素的索引原理。</p></blockquote><ul><li>多维数组以及其他数据类型的数组：</li></ul><blockquote><p>数组中的每个元素的数据类型不仅仅可以是数字，也可以是其他的。</p></blockquote><ul><li>字符串以及字符串操作：</li></ul><blockquote><p>当我们将char数组中的每一个位置存放一个字符的时候，这个数组就可以被看作是字符串了。于是针对字符串就会产生一系列的操作。</p></blockquote><p><strong>OK，所有的基础知识，都在这篇文章了。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484037&idx=1&sn=b20a1068e09add746179e0995bf58574&scene=21#wechat_redirect">C语言零基础入门—数组-01</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484069&idx=1&sn=9d6cc51ccd94e5181d4b62369b5a3d44&chksm=fca935e7cbdebcf1db8d46d47594fc9fb2029d751f382ba1abe9f8232a5329dc8e81ff1ae00f&scene=21#wechat_redirect">C语言零基础入门—数组-02</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484090&idx=1&sn=6f0c8ac2ff3666e2c6faa89456bc418c&chksm=fca935f8cbdebcee5fda6787e2ce4b3ead884993013689b690cc371e4fc41028fe6969c7f200&scene=21#wechat_redirect">C语言零基础入门—数组-03</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484121&idx=1&sn=50de0d42c1e4ba2284d9ddf83e424abb&chksm=fca9359bcbdebc8d8e5a3e529de8b778dc32a062f8b739422fd058971fdd531c045ad0e2cbe5&scene=21#wechat_redirect">C语言零基础入门—数组-04</a></p><h2 id="9-函数"><a href="#9-函数" class="headerlink" title="9. 函数"></a>9. 函数</h2><ul><li>随着学习的深入，发现main中放的代码越来越多，并且有很多代码重复写了多次，导致main越来越臃肿；于是我们就打算把main中具有相同功能的代码抽取出来，这就叫做函数，给这段函数起一个名字，然后使用的时候只用调用这个函数名字就可以了。</li></ul><blockquote><p>举一个栗子：有一段代码功能是求两个数的和，于是就可以把这段代码抽取出来形成一个函数，起名为sum，然后每次求和的时候调用一下sum就好了。而不用重复的写sum中的代码段。</p></blockquote><p><strong>这一节需要学会的知识：</strong></p><ul><li>有关函数的基本知识：</li></ul><blockquote><p>要明白有无返回值的概念，实参形参的概念，main也是一个函数。</p></blockquote><ul><li>函数的简单定义与使用：</li></ul><blockquote><p>函数的简单定义以及使用，就是自己完成一些简单的功能函数。</p></blockquote><ul><li>函数的复杂使用：</li></ul><blockquote><p>嵌套，递归，函数中传递数组参数都是一些难的操作。</p></blockquote><ul><li>函数的一些小细节：</li></ul><blockquote><p>最后了解一下函数的声明式定义，以及全局、局部变量的概念。</p></blockquote><p><strong>OK，所有的基础知识，都在这篇文章了。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484162&idx=1&sn=d8846981f59b4646a61351d999d75280&chksm=fca93440cbdebd561e460b4091c9533d063d9c74e597b1b9b59cd43375490af9e77dad10d183&scene=21#wechat_redirect">C语言零基础入门—函数-01</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484186&idx=1&sn=d8e4e4a35c81c033ab1d30f1de63b771&chksm=fca93458cbdebd4ebc85a82209026deffaf681545efc68343b0dc5b648b782e99d55d6b94888&scene=21#wechat_redirect">C语言零基础入门—函数-02</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484196&idx=1&sn=a6752bc8686981b77aeaa9bdbe856bae&scene=21#wechat_redirect">C语言零基础入门—函数-03</a></p><h2 id="10-指针"><a href="#10-指针" class="headerlink" title="10. 指针"></a>10. 指针</h2><ul><li>指针是C语言的精华所在，指针提供给用户可以<strong>直接操作内存地址</strong>的功能，其他语言都是屏蔽了这个功能，正是由于指针的存在C语言才变得强大，同时也是因为指针的存在C语言才变得不安全。</li></ul><blockquote><p>举一个栗子：有一个变量 <code>int a = 3;</code> 平常修改数据的方式是使用变量a来操作的，当使用指针的时候，可以直接找到电脑内存中的这个3所在的地址，直接修改，而不用通过变量a。</p></blockquote><p><strong>这一节需要学会的知识：</strong></p><ul><li>明白指针的工作原理，以及内存原理：</li></ul><blockquote><p>指针就是地址，地址就是内存中存放实际数据的空间。</p></blockquote><ul><li>区分开指针，指针变量的关系：</li></ul><blockquote><p>指针是地址，指针变量是指向指针的一个变量而已。</p></blockquote><p><strong>另注：取地址是 <code>&amp;</code> 符号，取数据是 <code>*</code> 符号。</strong></p><ul><li>使用指针操作简单的数据类型的数据：</li></ul><blockquote><p>使用指针操作int，float，char等简单数据类型。</p></blockquote><ul><li>使用指针操作数组：</li></ul><blockquote><p>使用指针操作一维数组，二维数组。</p></blockquote><ul><li>使用指针在函数之间传递参数：</li></ul><blockquote><p>有了指针之后，函数之间传递数组参数的时候就可以直接把地址传递就可以了。</p></blockquote><p><strong>OK，所有的基础知识，都在这篇文章了。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484241&idx=1&sn=10bf6fd2b542178746a55ee6b359d5ea&scene=21#wechat_redirect">C语言零基础入门-指针-01</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484259&idx=1&sn=4299204e35ce155f0170da17ee9d711e&chksm=fca93421cbdebd3743916eddff99d1e19b0458d871e99b6438cd0bc56cfb41298cb3ddbf2ba8&scene=21#wechat_redirect">C语言零基础入门-指针-02</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484291&idx=1&sn=04d01b4473462870d8b97b3490e02fb0&chksm=fca934c1cbdebdd7c9b6ac991525607350874885ef845819f634cb07dceb95e29d7698e1b308&scene=21#wechat_redirect">C语言零基础入门-指针-03</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484312&idx=1&sn=71df32298473ebf2a19cc8d7594a5c0e&chksm=fca934dacbdebdcc30115c8ca6515d16044d6ac85c3ac0847f9ff8a188c7c0c475e45a8d4b38&scene=21#wechat_redirect">C语言零基础入门-指针-04</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484335&idx=1&sn=88f306b93cf2109366386ba5090afc8c&chksm=fca934edcbdebdfbd04a9eca7bd837a42d790717a59c9feb5d194d289a99f8b40888bce2e5cc&scene=21#wechat_redirect">C语言零基础入门-指针-05</a></p><h2 id="11-结构体"><a href="#11-结构体" class="headerlink" title="11. 结构体"></a>11. 结构体</h2><ul><li>接触越来越多的需求之后，你会发现简单的数据类型int，float，char等等根本不够用了，于是就需要使用结构体自定义一些数据类型来使用。</li></ul><blockquote><p>举一个栗子：我们要自定义一个 student 数据类型，但是C语言中并没有这个数据类型，怎么办呢？我们可以通过结构体将基础的数据类型int，char，数组等等组织起来，形成一个我们自定义的数据类型，并且给他起一个名字叫做 student。这就是自定义的一个数据类型。</p></blockquote><p><strong>这一节需要学会的知识：</strong></p><ul><li>需要明白什么是结构体，它是什么作用：</li></ul><blockquote><p>结构体可以自定义数据类型，它通过将基础数据类型int，char，float等等数据类型进行人工拼接，形成一个我们需要的数据类型。</p></blockquote><ul><li>结构体怎么定义与使用：</li></ul><blockquote><p>结构体需要先定义出来才可以使用。</p></blockquote><ul><li>结构体类型的数组，指针怎么定义与使用：</li></ul><blockquote><p>结构体定义出来之后，其实和int的使用基本没什么区别，int可以定义数组，那么结构体当然也可以。int可以定义指针，结构体当然也可以吖。</p></blockquote><p><strong>OK，所有的基础知识，都在这篇文章了。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484364&idx=1&sn=8079f1c6687055518b2a3468a6433903&chksm=fca9348ecbdebd9832e2cb26efbd939c66dd6b30849ab800224ffb0e99a7b85182fe4dbc2394&scene=21#wechat_redirect">C语言零基础入门-结构体-01</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484521&idx=1&sn=4943495734463ca4d3289a14ff538d01&chksm=fca9332bcbdeba3d4f929af7669e9e9f04cab780fe3b376fd483fcbe670fd9fe6f59734a962f&scene=21#wechat_redirect">C语言零基础入门-结构体-02</a></p><h2 id="12-文件"><a href="#12-文件" class="headerlink" title="12. 文件"></a>12. 文件</h2><ul><li>最后，所有的编程语言都是可以操作文件的，因为程序运行起来之后的所有数据都是临时的，如果不存放在文件或者数据库中，那么当程序运行结束之后，数据就会消失，目前没有学习数据库，那么就把数据存放在文件中吧。</li></ul><p><strong>这一节需要学会的知识：</strong></p><ul><li>计算机中的路径要有所了解：</li></ul><blockquote><p>相对路径，绝对路径要很熟练。</p></blockquote><ul><li>文件打开，关闭，读写模式要知道：</li></ul><blockquote><p>其实文件打开关闭，读写都是一些模板而已，你记住就可以了。</p></blockquote><p><strong>OK，所有的基础知识，都在这篇文章了。</strong></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjY5ODU0MQ==&mid=2247484624&idx=1&sn=b0003dec4f05777293ca15e9122ea441&scene=21#wechat_redirect">C语言零基础入门-文件</a></p><h2 id="13-项目"><a href="#13-项目" class="headerlink" title="13. 项目"></a>13. 项目</h2><p>到这里为止，C语言的知识点就更新完了，最终带着大家做了一个小项目，可以看下边的两个连接。</p><p><a href="https://www.bilibili.com/video/BV1ga4y1p71g">C语言学生信息管理系统演示</a></p><p><a href="https://www.bilibili.com/video/BV1Yf4y1e7sz">C语言学生信息管理系统程序讲解</a></p><p><strong>okk，C语言撒花结束。</strong>希望大家多多关注我的公众号与B站哦：<strong>小小猿笔记</strong></p><p><img src="https://gitee.com/xiaoxiaojieya/blogimage/raw/master/img/%E5%85%AC%E4%BC%97%E5%8F%B7%E4%BA%8C%E7%BB%B4%E7%A0%81%20(2).jpg" alt="公众号二维码"></p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Blog开篇</title>
      <link href="2021/02/12/blog-kai-pian/"/>
      <url>2021/02/12/blog-kai-pian/</url>
      
        <content type="html"><![CDATA[<h2 id="01-开篇"><a href="#01-开篇" class="headerlink" title="01. 开篇"></a>01. 开篇</h2><blockquote><p>记录一下时间。</p></blockquote><p>现在是 <code>2021-02-12 08:39：07</code>，也就是新年的第一天，本来博客已经于前两天上线完毕，但是为了有一些纪念性的意义，于是从新上线一下，删除掉测试文章，正常的来这一篇 首发Blog。</p><h2 id="02-正文"><a href="#02-正文" class="headerlink" title="02. 正文"></a>02. 正文</h2><blockquote><p>闲扯几句。</p></blockquote><h3 id="02-1-关于我"><a href="#02-1-关于我" class="headerlink" title="02.1 关于我"></a>02.1 关于我</h3><p>本身自己已经做 <code>公众号+知乎+B站</code>（同名：小小猿笔记） 已经差不多一年了，但是粉丝数量不尽人意，没事没事，贵在坚持嘛，而且这种知识分享的过程本身就是一个知识沉淀的过程，知识永远不会被淘汰，沉淀的越久越香。</p><p><img src="https://gitee.com/xiaoxiaojieya/blogimage/raw/master/img/%E5%A4%AA%E9%9A%BE%E4%BA%86.jpg"></p><h3 id="02-2-关于Blog"><a href="#02-2-关于Blog" class="headerlink" title="02.2 关于Blog"></a>02.2 关于Blog</h3><p>再谈谈为什么要做这个Blog，本身一直使用的是第三方推文平台，但是慢慢的发现局限性太大，推文数量以及推文形式都会被限制，于是就打算自己做这个，来归一化所有的可用形式，至于如何归一化慢慢地往后大家就会发现了。</p><p>这个Blog会慢慢的将其他平台的推文从新整理发布到这里，并且会整理出较好的标签、类别方便大家观看，并且会分享一下自己的生活趣事以及常用工具在指定页面。</p><p>希望大家会喜欢。</p><img src="https://gitee.com/xiaoxiaojieya/blogimage/raw/master/img/%E5%98%BB%E5%98%BB%E5%98%BB.jpg" style="zoom:23%;" /><h2 id="03-1-结尾"><a href="#03-1-结尾" class="headerlink" title="03.1 结尾"></a>03.1 结尾</h2><blockquote><p>新年快乐。</p></blockquote><p>本身我就不善于什么言辞，所以，就这样结尾吧，大家新年快乐，万事如意。</p><p><strong>公众号</strong>：<strong>小小猿笔记</strong></p><p><strong>知乎</strong>：<strong>小小猿笔记</strong></p><p><strong>B站</strong>：<strong>小小猿笔记</strong></p><p><img src="https://gitee.com/xiaoxiaojieya/blogimage/raw/master/img/%E5%85%AC%E4%BC%97%E5%8F%B7%E4%BA%8C%E7%BB%B4%E7%A0%81%20(2).jpg"></p>]]></content>
      
      
      <categories>
          
          <category> 个人 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 概述 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
